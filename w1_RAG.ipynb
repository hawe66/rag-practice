{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# RAG ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬ì¶• - AI Agent & RAG ì£¼ì œ\n",
    "\n",
    "## Milestone 1: ë¬¸ì„œ ìˆ˜ì§‘ ë° ë¡œë“œ\n",
    "- ì£¼ì œ: AI Agent & RAG ê´€ë ¨ ê¸°ìˆ  ë¸”ë¡œê·¸\n",
    "- ë¬¸ì„œ ìˆ˜: 5ê°œ (LangChain ê³µì‹ ë¬¸ì„œ ë° ë¸”ë¡œê·¸)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# API KEY ì •ë³´ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "milestone1",
   "metadata": {},
   "source": [
    "## 1. ë¬¸ì„œ ë¡œë“œ - AI Agent & RAG ê¸°ìˆ  ë¸”ë¡œê·¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "load_docs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ 5ê°œì˜ ë¬¸ì„œê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "[ë¬¸ì„œ 1]\n",
      "URL: https://python.langchain.com/docs/tutorials/rag/\n",
      "ë‚´ìš© ê¸¸ì´: 22360 characters\n",
      "ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: Build a RAG agent with LangChain - Docs by LangChainSkip to main contentï£¿Ã¼Ã¶Ã„ Share how you're building agents for a chance to win LangChain swag!Docs by LangChain home pageLangChain + LangGraphSearch....\n",
      "--------------------------------------------------------------------------------\n",
      "[ë¬¸ì„œ 2]\n",
      "URL: https://python.langchain.com/docs/concepts/vectorstores/\n",
      "ë‚´ìš© ê¸¸ì´: 3912 characters\n",
      "ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: LangChain overview - Docs by LangChainSkip to main contentÃ°Å¸Å¡â‚¬ Share how you're building agents for a chance to win LangChain swag!Docs by LangChain home pageLangChain + LangGraphSearch...Ã¢Å’ËœKAsk AIGi...\n",
      "--------------------------------------------------------------------------------\n",
      "[ë¬¸ì„œ 3]\n",
      "URL: https://python.langchain.com/docs/concepts/text_splitters/\n",
      "ë‚´ìš© ê¸¸ì´: 3912 characters\n",
      "ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: LangChain overview - Docs by LangChainSkip to main contentÃ°Å¸Å¡â‚¬ Share how you're building agents for a chance to win LangChain swag!Docs by LangChain home pageLangChain + LangGraphSearch...Ã¢Å’ËœKAsk AIGi...\n",
      "--------------------------------------------------------------------------------\n",
      "[ë¬¸ì„œ 4]\n",
      "URL: https://python.langchain.com/docs/concepts/embedding_models/\n",
      "ë‚´ìš© ê¸¸ì´: 3912 characters\n",
      "ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: LangChain overview - Docs by LangChainSkip to main contentÃ°Å¸Å¡â‚¬ Share how you're building agents for a chance to win LangChain swag!Docs by LangChain home pageLangChain + LangGraphSearch...Ã¢Å’ËœKAsk AIGi...\n",
      "--------------------------------------------------------------------------------\n",
      "[ë¬¸ì„œ 5]\n",
      "URL: https://blog.langchain.dev/deconstructing-rag/\n",
      "ë‚´ìš© ê¸¸ì´: 11241 characters\n",
      "ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: \n",
      "\n",
      "\n",
      "Deconstructing RAG\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Case Studies\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "In the Loop\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LangChain\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Changelog\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sign in\n",
      "Subscribe\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# AI Agent & RAG ê´€ë ¨ ê¸°ìˆ  ë¸”ë¡œê·¸ URL\n",
    "urls = [\n",
    "    \"https://python.langchain.com/docs/tutorials/rag/\",\n",
    "    \"https://python.langchain.com/docs/concepts/vectorstores/\",\n",
    "    \"https://python.langchain.com/docs/concepts/text_splitters/\",\n",
    "    \"https://python.langchain.com/docs/concepts/embedding_models/\",\n",
    "    \"https://blog.langchain.dev/deconstructing-rag/\"\n",
    "]\n",
    "\n",
    "# Document Loader ì„¤ì •\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=urls,\n",
    "    # bs_kwargs=dict(\n",
    "    #     parse_only=bs4.SoupStrainer(\n",
    "    #         class_=(\"post-content\", \"post-title\", \"post-header\", \"article\")\n",
    "    #     )\n",
    "    # ),\n",
    ")\n",
    "\n",
    "# ë¬¸ì„œ ë¡œë“œ\n",
    "docs = loader.load()\n",
    "\n",
    "# ë¡œë“œ í™•ì¸\n",
    "print(f\"ì´ {len(docs)}ê°œì˜ ë¬¸ì„œê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\\n\")\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"[ë¬¸ì„œ {i+1}]\")\n",
    "    print(f\"URL: {doc.metadata.get('source', 'Unknown')}\")\n",
    "    print(f\"ë‚´ìš© ê¸¸ì´: {len(doc.page_content)} characters\")\n",
    "    print(f\"ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {doc.page_content[:200]}...\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "milestone2",
   "metadata": {},
   "source": [
    "## 2. ì²­í‚¹ ì „ëµ ë¹„êµ (Milestone 2)\n",
    "\n",
    "### 2-1. CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "char_splitter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1250, which is longer than the specified 1000\n",
      "Created a chunk of size 1106, which is longer than the specified 1000\n",
      "Created a chunk of size 1817, which is longer than the specified 1000\n",
      "Created a chunk of size 2111, which is longer than the specified 1000\n",
      "Created a chunk of size 2111, which is longer than the specified 1000\n",
      "Created a chunk of size 2111, which is longer than the specified 1000\n",
      "Created a chunk of size 10640, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharacterTextSplitter ê²°ê³¼:\n",
      "- ì´ ì²­í¬ ìˆ˜: 42\n",
      "- ì²« ë²ˆì§¸ ì²­í¬ ê¸¸ì´: 1250 characters\n",
      "- ì²« ë²ˆì§¸ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°:\n",
      "Build a RAG agent with LangChain - Docs by LangChainSkip to main contentï£¿Ã¼Ã¶Ã„ Share how you're building agents for a chance to win LangChain swag!Docs by LangChain home pageLangChain + LangGraphSearch...â€šÃ¥Ã²KAsk AIGitHubTry LangSmithTry LangSmithSearch...NavigationLangChainBuild a RAG agent with LangC...\n"
     ]
    }
   ],
   "source": [
    "# CharacterTextSplitter ì ìš©\n",
    "char_text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "char_splits = char_text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"CharacterTextSplitter ê²°ê³¼:\")\n",
    "print(f\"- ì´ ì²­í¬ ìˆ˜: {len(char_splits)}\")\n",
    "print(f\"- ì²« ë²ˆì§¸ ì²­í¬ ê¸¸ì´: {len(char_splits[0].page_content)} characters\")\n",
    "print(f\"- ì²« ë²ˆì§¸ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°:\\n{char_splits[0].page_content[:300]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recursive_header",
   "metadata": {},
   "source": [
    "### 2-2. RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "recursive_splitter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveCharacterTextSplitter ê²°ê³¼:\n",
      "- ì´ ì²­í¬ ìˆ˜: 63\n",
      "- ì²« ë²ˆì§¸ ì²­í¬ ê¸¸ì´: 854 characters\n",
      "- ì²« ë²ˆì§¸ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°:\n",
      "Build a RAG agent with LangChain - Docs by LangChainSkip to main contentï£¿Ã¼Ã¶Ã„ Share how you're building agents for a chance to win LangChain swag!Docs by LangChain home pageLangChain + LangGraphSearch...â€šÃ¥Ã²KAsk AIGitHubTry LangSmithTry LangSmithSearch...NavigationLangChainBuild a RAG agent with LangC...\n"
     ]
    }
   ],
   "source": [
    "# RecursiveCharacterTextSplitter ì ìš©\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "recursive_splits = recursive_text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"RecursiveCharacterTextSplitter ê²°ê³¼:\")\n",
    "print(f\"- ì´ ì²­í¬ ìˆ˜: {len(recursive_splits)}\")\n",
    "print(f\"- ì²« ë²ˆì§¸ ì²­í¬ ê¸¸ì´: {len(recursive_splits[0].page_content)} characters\")\n",
    "print(f\"- ì²« ë²ˆì§¸ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°:\\n{recursive_splits[0].page_content[:300]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison",
   "metadata": {},
   "source": [
    "### 2-3. ì²­í‚¹ ì „ëµ ë¹„êµ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "compare_splitters",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ì²­í‚¹ ì „ëµ ë¹„êµ\n",
      "================================================================================\n",
      "\n",
      "1. CharacterTextSplitter:\n",
      "   - ì´ ì²­í¬ ìˆ˜: 42\n",
      "   - í‰ê·  ì²­í¬ ê¸¸ì´: 1091 characters\n",
      "   - íŠ¹ì§•: ë‹¨ìˆœ êµ¬ë¶„ì(\\n\\n) ê¸°ë°˜ ë¶„í• \n",
      "\n",
      "2. RecursiveCharacterTextSplitter:\n",
      "   - ì´ ì²­í¬ ìˆ˜: 63\n",
      "   - í‰ê·  ì²­í¬ ê¸¸ì´: 751 characters\n",
      "   - íŠ¹ì§•: ê³„ì¸µì  êµ¬ë¶„ì ì‚¬ìš©, ë¬¸ë§¥ ë³´ì¡´ ìš°ìˆ˜\n",
      "\n",
      "ğŸ’¡ ì¶”ì²œ: RecursiveCharacterTextSplitter\n",
      "   - ë” ì¼ê´€ëœ ì²­í¬ í¬ê¸°\n",
      "   - ë¬¸ë§¥ì„ ë” ì˜ ë³´ì¡´\n",
      "   - ì½”ë“œ ë¸”ë¡ê³¼ êµ¬ì¡°ë¥¼ ì˜ ìœ ì§€\n",
      "\n",
      "âœ… ìµœì¢… ì„ íƒ: RecursiveCharacterTextSplitter (63 chunks)\n"
     ]
    }
   ],
   "source": [
    "# ì²­í‚¹ ì „ëµ ë¹„êµ\n",
    "print(\"=\" * 80)\n",
    "print(\"ì²­í‚¹ ì „ëµ ë¹„êµ\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n1. CharacterTextSplitter:\")\n",
    "print(f\"   - ì´ ì²­í¬ ìˆ˜: {len(char_splits)}\")\n",
    "print(f\"   - í‰ê·  ì²­í¬ ê¸¸ì´: {sum(len(chunk.page_content) for chunk in char_splits) / len(char_splits):.0f} characters\")\n",
    "print(f\"   - íŠ¹ì§•: ë‹¨ìˆœ êµ¬ë¶„ì(\\\\n\\\\n) ê¸°ë°˜ ë¶„í• \")\n",
    "\n",
    "print(f\"\\n2. RecursiveCharacterTextSplitter:\")\n",
    "print(f\"   - ì´ ì²­í¬ ìˆ˜: {len(recursive_splits)}\")\n",
    "print(f\"   - í‰ê·  ì²­í¬ ê¸¸ì´: {sum(len(chunk.page_content) for chunk in recursive_splits) / len(recursive_splits):.0f} characters\")\n",
    "print(f\"   - íŠ¹ì§•: ê³„ì¸µì  êµ¬ë¶„ì ì‚¬ìš©, ë¬¸ë§¥ ë³´ì¡´ ìš°ìˆ˜\")\n",
    "\n",
    "print(\"\\nğŸ’¡ ì¶”ì²œ: RecursiveCharacterTextSplitter\")\n",
    "print(\"   - ë” ì¼ê´€ëœ ì²­í¬ í¬ê¸°\")\n",
    "print(\"   - ë¬¸ë§¥ì„ ë” ì˜ ë³´ì¡´\")\n",
    "print(\"   - ì½”ë“œ ë¸”ë¡ê³¼ êµ¬ì¡°ë¥¼ ì˜ ìœ ì§€\")\n",
    "\n",
    "# ìµœì¢… ì„ íƒ\n",
    "splits = recursive_splits\n",
    "print(f\"\\nâœ… ìµœì¢… ì„ íƒ: RecursiveCharacterTextSplitter ({len(splits)} chunks)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "milestone3",
   "metadata": {},
   "source": [
    "## 3. ì„ë² ë”© ë° ë²¡í„° ì €ì¥ (Milestone 3)\n",
    "\n",
    "### 3-1. FAISS ë²¡í„°ìŠ¤í† ì–´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faiss_vectorstore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ\n",
      "   - ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: 63\n",
      "   - ì„ë² ë”© ëª¨ë¸: OpenAI text-embedding-ada-002\n"
     ]
    }
   ],
   "source": [
    "# OpenAI ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„±\n",
    "vectorstore_faiss = FAISS.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(\"âœ… FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"   - ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: {len(splits)}\")\n",
    "print(f\"   - ì„ë² ë”© ëª¨ë¸: OpenAI text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chroma_header",
   "metadata": {},
   "source": [
    "### 3-2. Chroma ë²¡í„°ìŠ¤í† ì–´ (ëŒ€ì•ˆ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "chroma_vectorstore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Chroma ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ\n",
      "   - ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: 63\n",
      "   - ì„ë² ë”© ëª¨ë¸: OpenAI text-embedding-ada-002\n"
     ]
    }
   ],
   "source": [
    "# Chroma ë²¡í„°ìŠ¤í† ì–´ ìƒì„± (ì„ íƒì‚¬í•­)\n",
    "vectorstore_chroma = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(\"âœ… Chroma ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"   - ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: {len(splits)}\")\n",
    "print(f\"   - ì„ë² ë”© ëª¨ë¸: OpenAI text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choose_vectorstore",
   "metadata": {},
   "source": [
    "### 3-3. ë²¡í„°ìŠ¤í† ì–´ ì„ íƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "select_vectorstore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Retriever ì„¤ì • ì™„ë£Œ\n",
      "   - ë²¡í„°ìŠ¤í† ì–´: Chroma\n",
      "   - ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: 4\n"
     ]
    }
   ],
   "source": [
    "# ìµœì¢… ì‚¬ìš©í•  ë²¡í„°ìŠ¤í† ì–´ ì„ íƒ (FAISS ì‚¬ìš©)\n",
    "vectorstore = vectorstore_chroma\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 4}  # ìƒìœ„ 4ê°œ ê²°ê³¼ ë°˜í™˜\n",
    ")\n",
    "\n",
    "print(\"âœ… Retriever ì„¤ì • ì™„ë£Œ\")\n",
    "print(f\"   - ë²¡í„°ìŠ¤í† ì–´: Chroma\")\n",
    "print(f\"   - ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "milestone4",
   "metadata": {},
   "source": [
    "## 4. ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸ (Milestone 4)\n",
    "\n",
    "### 4-1. RAG í”„ë¡¬í”„íŠ¸ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "setup_prompt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RAG í”„ë¡¬í”„íŠ¸ ì„¤ì • ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# RAG í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"ë‹¹ì‹ ì€ AI Agentì™€ RAG ì‹œìŠ¤í…œì— ëŒ€í•œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. \n",
    "ì£¼ì–´ì§„ ë¬¸ë§¥(context)ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸(question)ì— ì •í™•í•˜ê³  ìƒì„¸í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ë‹µë³€ ì‹œ ì£¼ì˜ì‚¬í•­:\n",
    "1. ì£¼ì–´ì§„ ë¬¸ë§¥ì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” ì •ë³´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\n",
    "2. ë‹µì„ ëª¨ë¥´ë©´ \"ì£¼ì–´ì§„ ì •ë³´ì—ì„œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤\"ë¼ê³  ë‹µí•˜ì„¸ìš”.\n",
    "3. ê¸°ìˆ  ìš©ì–´ëŠ” ì›ë¬¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì„¸ìš” (ì˜ˆ: RAG, Vector Store, Embedding).\n",
    "4. ê°€ëŠ¥í•˜ë©´ êµ¬ì²´ì ì¸ ì˜ˆì‹œë‚˜ ì½”ë“œë¥¼ í¬í•¨í•˜ì„¸ìš”.\n",
    "\n",
    "#Question: \n",
    "{question} \n",
    "\n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "print(\"âœ… RAG í”„ë¡¬í”„íŠ¸ ì„¤ì • ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_chain",
   "metadata": {},
   "source": [
    "### 4-2. RAG Chain êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "create_chain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RAG Chain êµ¬ì„± ì™„ë£Œ\n",
      "   - LLM: gpt-4o-mini\n",
      "   - Temperature: 0.0\n"
     ]
    }
   ],
   "source": [
    "# LLM ì„¤ì •\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# RAG ì²´ì¸ ìƒì„±\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"âœ… RAG Chain êµ¬ì„± ì™„ë£Œ\")\n",
    "print(f\"   - LLM: {llm.model_name}\")\n",
    "print(f\"   - Temperature: {llm.temperature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_questions",
   "metadata": {},
   "source": [
    "### 4-3. í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ (ìµœì†Œ 3ê°œ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "test1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ì§ˆë¬¸ 1: RAGë€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "================================================================================\n",
      "RAG( Retrieval-Augmented Generation)ë€ ì •ë³´ ê²€ìƒ‰(data retrieval)ê³¼ ìƒì„±(generation) ëª¨ë¸ì„ ê²°í•©í•œ ì ‘ê·¼ ë°©ì‹ì…ë‹ˆë‹¤. RAGëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ê¸° ìœ„í•´ ì™¸ë¶€ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ ê²€ìƒ‰ëœ ì •ë³´ë¥¼ LLM(ëŒ€í˜• ì–¸ì–´ ëª¨ë¸)ì—ê²Œ í”„ë¡¬í”„íŠ¸ì˜ ì¼ë¶€ë¡œ ì „ë‹¬í•˜ëŠ” ê³¼ì •ì„ í¬í•¨í•©ë‹ˆë‹¤.\n",
      "\n",
      "RAGì˜ ì‘ë™ ë°©ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥**: ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
      "2. **ì •ë³´ ê²€ìƒ‰**: ì…ë ¥ëœ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ ì¿¼ë¦¬ ë³€í™˜(query transformations) ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì…ë ¥ì„ ìˆ˜ì •í•˜ì—¬ ê²€ìƒ‰ì˜ ì •í™•ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "3. **LLMì— ì •ë³´ ì „ë‹¬**: ê²€ìƒ‰ëœ ë¬¸ì„œì™€ ì´ˆê¸° ì§ˆë¬¸ì„ LLMì— ì „ë‹¬í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "4. **ë‹µë³€ ë°˜í™˜**: LLMì´ ìƒì„±í•œ ë‹µë³€ì„ ì‚¬ìš©ìì—ê²Œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´, LangChainì„ ì‚¬ìš©í•˜ì—¬ RAG ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒì€ ê°„ë‹¨í•œ RAG ì—ì´ì „íŠ¸ë¥¼ êµ¬í˜„í•˜ëŠ” ì½”ë“œì˜ ì˜ˆì‹œì…ë‹ˆë‹¤:\n",
      "\n",
      "```python\n",
      "from langchain.tools import tool\n",
      "\n",
      "@tool\n",
      "def search_documents(query):\n",
      "    # ì´ í•¨ìˆ˜ëŠ” ì£¼ì–´ì§„ ì¿¼ë¦¬ì— ëŒ€í•´ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ë¡œì§ì„ í¬í•¨í•©ë‹ˆë‹¤.\n",
      "    pass\n",
      "\n",
      "def rag_agent(user_question):\n",
      "    # ë¬¸ì„œ ê²€ìƒ‰\n",
      "    retrieved_docs = search_documents(user_question)\n",
      "    \n",
      "    # LLMì— ì§ˆë¬¸ê³¼ ê²€ìƒ‰ëœ ë¬¸ì„œ ì „ë‹¬\n",
      "    answer = llm.generate_answer(user_question, retrieved_docs)\n",
      "    \n",
      "    return answer\n",
      "```\n",
      "\n",
      "ì´ì™€ ê°™ì´ RAGëŠ” ì •ë³´ ê²€ìƒ‰ê³¼ ìƒì„± ëª¨ë¸ì„ ê²°í•©í•˜ì—¬ ë³´ë‹¤ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ 1: RAG ê¸°ë³¸ ê°œë…\n",
    "print(\"=\"*80)\n",
    "print(\"ì§ˆë¬¸ 1: RAGë€ ë¬´ì—‡ì¸ê°€ìš”?\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "answer1 = rag_chain.invoke(\"RAGë€ ë¬´ì—‡ì¸ê°€ìš”? ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”?\")\n",
    "print(answer1)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c3e25af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ì§ˆë¬¸ ì…ë ¥\n",
    "question = \"RAGë€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "\n",
    "# 2. Retrieverê°€ ìë™ìœ¼ë¡œ ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹¤í–‰\n",
    "# (ë‚´ë¶€ì ìœ¼ë¡œ)\n",
    "query_embedding = OpenAIEmbeddings().embed_query(question)\n",
    "# [0.234, -0.123, 0.456, ...] (1536ì°¨ì›)\n",
    "\n",
    "# Chroma DBì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰\n",
    "similar_docs = vectorstore.similarity_search_by_vector(\n",
    "    embedding=query_embedding,\n",
    "    k=4\n",
    ")\n",
    "# ê²°ê³¼: [doc1, doc3, doc5, doc7] (ê°€ì¥ ìœ ì‚¬í•œ 4ê°œ)\n",
    "\n",
    "# 3. ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ contextë¡œ ì „ë‹¬\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in similar_docs])\n",
    "\n",
    "# 4. í”„ë¡¬í”„íŠ¸ì— ì‚½ì…\n",
    "filled_prompt = f\"\"\"\n",
    "ì§ˆë¬¸: {question}\n",
    "\n",
    "ë¬¸ë§¥: {context}\n",
    "\n",
    "ë‹µë³€:\n",
    "\"\"\"\n",
    "\n",
    "# 5. LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±\n",
    "answer = llm.invoke(filled_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99b14d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='f22f4b02-7a1b-45ca-8947-ace036e6e9d4', metadata={'source': 'https://blog.langchain.dev/deconstructing-rag/', 'language': 'en', 'title': 'Deconstructing RAG'}, page_content='information from a data source (or sources), and a process of passing the retrieved information directly to the LLM as part of the prompt (see an example prompt in LangChain hub here).ChallengeThe landscape of RAG methods has expanded greatly in recent months, resulting in some degree of overload or confusion among users about where to start and how to think about the various approaches. Over the past few months, we have worked to group RAG concepts into a few categories and have released guides for each. Below we\\'ll provide a round-up of these concepts and present some future work. Major RAG themesQuery TransformationsA first question to ask when thinking about RAG: how can we make retrieval robust to variability in user input? For example, user questions may be poorly worded for the challenging task of retrieval. Query transformations are a set of approaches focused on modifying the user input in order to improve retrieval. Query expansionConsider the question \"Who won a'), Document(id='a9b86941-cfbb-4da2-9527-e132700df6b0', metadata={'title': 'Deconstructing RAG', 'source': 'https://blog.langchain.dev/deconstructing-rag/', 'language': 'en'}, page_content='Deconstructing RAG\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCase Studies\\n\\n\\n\\n\\nIn the Loop\\n\\n\\n\\n\\nLangChain\\n\\n\\n\\n\\nDocs\\n\\n\\n\\n\\nChangelog\\n\\n\\n\\n\\n\\nSign in\\nSubscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDeconstructing RAG\\n\\n7 min read\\nNov 30, 2023'), Document(id='710e5c9b-178a-488a-8c0d-7b9616fd0594', metadata={'source': 'https://python.langchain.com/docs/tutorials/rag/', 'title': 'Build a RAG agent with LangChain - Docs by LangChain', 'language': 'en'}, page_content='We can see the full sequence of steps, along with latency and other metadata, in the LangSmith trace.\\nYou can add a deeper level of control and customization using the LangGraph framework directlyâ€šÃ„Ã® for example, you can add steps to grade document relevance and rewrite search queries. Check out LangGraphâ€šÃ„Ã´s Agentic RAG tutorial for more advanced formulations.\\nâ€šÃ„Ã£RAG chains\\nIn the above agentic RAG formulation we allow the LLM to use its discretion in generating a tool call to help answer user queries. This is a good general-purpose solution, but comes with some trade-offs:'), Document(id='f6307b76-7ffb-4c6e-9c24-e0b145211adc', metadata={'language': 'en', 'source': 'https://python.langchain.com/docs/tutorials/rag/', 'title': 'Build a RAG agent with LangChain - Docs by LangChain'}, page_content='Now letâ€šÃ„Ã´s write the actual application logic. We want to create a simple application that takes a user question, searches for documents relevant to that question, passes the retrieved documents and initial question to a model, and returns an answer.\\nWe will demonstrate:\\n\\nA RAG agent that executes searches with a simple tool. This is a good general-purpose implementation.\\nA two-step RAG chain that uses just a single LLM call per query. This is a fast and effective method for simple queries.\\n\\nâ€šÃ„Ã£RAG agents\\nOne formulation of a RAG application is as a simple agent with a tool that retrieves information. We can assemble a minimal RAG agent by implementing a tool that wraps our vector store:\\nCopyfrom langchain.tools import tool')]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "information from a data source (or sources), and a process of passing the retrieved information directly to the LLM as part of the prompt (see an example prompt in LangChain hub here).ChallengeThe landscape of RAG methods has expanded greatly in recent months, resulting in some degree of overload or confusion among users about where to start and how to think about the various approaches. Over the past few months, we have worked to group RAG concepts into a few categories and have released guides for each. Below we'll provide a round-up of these concepts and present some future work. Major RAG themesQuery TransformationsA first question to ask when thinking about RAG: how can we make retrieval robust to variability in user input? For example, user questions may be poorly worded for the challenging task of retrieval. Query transformations are a set of approaches focused on modifying the user input in order to improve retrieval. Query expansionConsider the question \"Who won a\n",
      "\n",
      "Deconstructing RAG\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Case Studies\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "In the Loop\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LangChain\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Docs\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Changelog\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sign in\n",
      "Subscribe\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Deconstructing RAG\n",
      "\n",
      "7 min read\n",
      "Nov 30, 2023\n",
      "\n",
      "We can see the full sequence of steps, along with latency and other metadata, in the LangSmith trace.\n",
      "You can add a deeper level of control and customization using the LangGraph framework directlyâ€šÃ„Ã® for example, you can add steps to grade document relevance and rewrite search queries. Check out LangGraphâ€šÃ„Ã´s Agentic RAG tutorial for more advanced formulations.\n",
      "â€šÃ„Ã£RAG chains\n",
      "In the above agentic RAG formulation we allow the LLM to use its discretion in generating a tool call to help answer user queries. This is a good general-purpose solution, but comes with some trade-offs:\n",
      "\n",
      "Now letâ€šÃ„Ã´s write the actual application logic. We want to create a simple application that takes a user question, searches for documents relevant to that question, passes the retrieved documents and initial question to a model, and returns an answer.\n",
      "We will demonstrate:\n",
      "\n",
      "A RAG agent that executes searches with a simple tool. This is a good general-purpose implementation.\n",
      "A two-step RAG chain that uses just a single LLM call per query. This is a fast and effective method for simple queries.\n",
      "\n",
      "â€šÃ„Ã£RAG agents\n",
      "One formulation of a RAG application is as a simple agent with a tool that retrieves information. We can assemble a minimal RAG agent by implementing a tool that wraps our vector store:\n",
      "Copyfrom langchain.tools import tool\n",
      "----------------------------------------------------------------------------------------------------\n",
      "content='RAGëŠ” \"Retrieval-Augmented Generation\"ì˜ ì•½ìë¡œ, ì •ë³´ ê²€ìƒ‰ê³¼ ìƒì„± ëª¨ë¸ì„ ê²°í•©í•œ ì ‘ê·¼ ë°©ì‹ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì´ ë°©ë²•ì€ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ì— ëŒ€í•´ ê´€ë ¨ ì •ë³´ë¥¼ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ê²€ìƒ‰í•˜ê³ , ê·¸ ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)ì—ê²Œ ì „ë‹¬í•˜ì—¬ ë³´ë‹¤ ì •í™•í•˜ê³  í’ë¶€í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ê³¼ì •ì„ í¬í•¨í•©ë‹ˆë‹¤.\\n\\nRAGì˜ ì£¼ìš” êµ¬ì„± ìš”ì†ŒëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\\n\\n1. **ì •ë³´ ê²€ìƒ‰**: ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì°¾ê¸° ìœ„í•´ ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ ì¿¼ë¦¬ ë³€í™˜ê³¼ ê°™ì€ ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ì˜ ì •í™•ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\\n\\n2. **ì •ë³´ ìƒì„±**: ê²€ìƒ‰ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ë•Œ LLMì€ ê²€ìƒ‰ëœ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì˜ ì¼ë¶€ë¡œ ì‚¬ìš©í•˜ì—¬ ë³´ë‹¤ ë§¥ë½ì— ë§ëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.\\n\\nRAGì˜ ì¥ì ì€ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸ì´ ëª¨í˜¸í•˜ê±°ë‚˜ ì˜ëª»ëœ ê²½ìš°ì—ë„ ê²€ìƒ‰ëœ ì •ë³´ë¥¼ í†µí•´ ë³´ë‹¤ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ìµœê·¼ ëª‡ ë‹¬ ë™ì•ˆ RAG ë°©ë²•ë¡ ì´ ë‹¤ì–‘í•´ì§€ë©´ì„œ ì‚¬ìš©ìë“¤ì´ ì–´ë–¤ ì ‘ê·¼ ë°©ì‹ì„ ì„ íƒí•´ì•¼ í• ì§€ í˜¼ë€ìŠ¤ëŸ¬ì›Œí•˜ëŠ” ê²½ìš°ê°€ ë§ì•„ì¡ŒìŠµë‹ˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ RAG ê°œë…ì„ ëª‡ ê°€ì§€ ì¹´í…Œê³ ë¦¬ë¡œ ë‚˜ëˆ„ê³ , ê° ì¹´í…Œê³ ë¦¬ì— ëŒ€í•œ ê°€ì´ë“œë¥¼ ì œê³µí•˜ëŠ” ì‘ì—…ì´ ì§„í–‰ë˜ê³  ìˆìŠµë‹ˆë‹¤.\\n\\nRAGëŠ” ì •ë³´ ê²€ìƒ‰ê³¼ ìƒì„±ì˜ ê²°í•©ì„ í†µí•´ ë” ë‚˜ì€ ì‚¬ìš©ì ê²½í—˜ì„ ì œê³µí•˜ëŠ” í˜ì‹ ì ì¸ ë°©ë²•ìœ¼ë¡œ, ë‹¤ì–‘í•œ ì‘ìš© í”„ë¡œê·¸ë¨ì—ì„œ í™œìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 342, 'prompt_tokens': 544, 'total_tokens': 886, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CfO0e9Bs9EpohmtBt3ZWJ0oEDz72b', 'finish_reason': 'stop', 'logprobs': None} id='run--19973c6d-609f-4c5c-9dfb-d921bcb2ab36-0' usage_metadata={'input_tokens': 544, 'output_tokens': 342, 'total_tokens': 886, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(similar_docs)\n",
    "print('-'*100)\n",
    "print(context)\n",
    "print('-'*100)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "test2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ì§ˆë¬¸ 2: Text Splitterì˜ ì¢…ë¥˜ì™€ ì°¨ì´ì \n",
      "================================================================================\n",
      "ì£¼ì–´ì§„ ë¬¸ë§¥ì—ì„œ ì–¸ê¸‰ëœ Text Splitterì˜ ì¢…ë¥˜ëŠ” `RecursiveCharacterTextSplitter`ì…ë‹ˆë‹¤. ì´ Text SplitterëŠ” ë¬¸ì„œë¥¼ ê³µí†µ êµ¬ë¶„ì(ì˜ˆ: ì¤„ ë°”ê¿ˆ)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¬ê·€ì ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ê° ì²­í¬ê°€ ì ì ˆí•œ í¬ê¸°ê°€ ë˜ë„ë¡ í•©ë‹ˆë‹¤. ì´ëŠ” ì¼ë°˜ì ì¸ í…ìŠ¤íŠ¸ ì‚¬ìš© ì‚¬ë¡€ì— ê¶Œì¥ë˜ëŠ” í…ìŠ¤íŠ¸ ë¶„í• ê¸°ì…ë‹ˆë‹¤.\n",
      "\n",
      "ê° Text Splitterì˜ ì°¨ì´ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì •ë³´ëŠ” ì£¼ì–´ì§„ ë¬¸ë§¥ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë”°ë¼ì„œ, ì£¼ì–´ì§„ ì •ë³´ì—ì„œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ 2: Text Splitter\n",
    "print(\"=\"*80)\n",
    "print(\"ì§ˆë¬¸ 2: Text Splitterì˜ ì¢…ë¥˜ì™€ ì°¨ì´ì \")\n",
    "print(\"=\"*80)\n",
    "\n",
    "answer2 = rag_chain.invoke(\"Text Splitterì—ëŠ” ì–´ë–¤ ì¢…ë¥˜ê°€ ìˆê³ , ê°ê° ì–´ë–¤ ì°¨ì´ê°€ ìˆë‚˜ìš”?\")\n",
    "print(answer2)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "test3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ì§ˆë¬¸ 3: Vector Storeì˜ ì—­í• \n",
      "================================================================================\n",
      "Vector StoreëŠ” RAG ì‹œìŠ¤í…œì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ë§¥ì— ë”°ë¥´ë©´, Vector StoreëŠ” ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ê°ì‹¸ëŠ” ë˜í¼ë¡œì„œ, ì„ë² ë”©ì„ ì €ì¥í•˜ê³  ì¿¼ë¦¬í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. RAG ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì‘ë™ ë°©ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **Retrieve (ê²€ìƒ‰)**: ì‚¬ìš©ìì˜ ì…ë ¥ì— ë”°ë¼, ê´€ë ¨ëœ ë°ì´í„° ì¡°ê°ì´ Vector Storeì—ì„œ ê²€ìƒ‰ë©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ Retrieverê°€ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
      "2. **Generate (ìƒì„±)**: ê²€ìƒ‰ëœ ë°ì´í„°ì™€ ì§ˆë¬¸ì„ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´, ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´, Vector StoreëŠ” í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ” ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì˜ ì¡°ê°ì„ ê²€ìƒ‰í•˜ì—¬ ë°˜í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¡œ ì¸í•´ RAG ì‹œìŠ¤í…œì€ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. \n",
      "\n",
      "ë˜í•œ, Vector StoreëŠ” ë©”íƒ€ë°ì´í„° í•„í„°ë§ì„ í†µí•´ êµ¬ì¡°í™”ëœ ì¿¼ë¦¬ë¥¼ ì§€ì›í•˜ì—¬ ë¹„êµ¬ì¡°í™”ëœ ë¬¸ì„œë¥¼ í•„í„°ë§í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ë„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ê¸°ëŠ¥ì€ ìì—°ì–´ ì¿¼ë¦¬ë¥¼ ë©”íƒ€ë°ì´í„° í•„ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ êµ¬ì¡°í™”ëœ ì¿¼ë¦¬ë¡œ ë³€í™˜í•˜ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤. \n",
      "\n",
      "ê²°ë¡ ì ìœ¼ë¡œ, Vector StoreëŠ” RAG ì‹œìŠ¤í…œì—ì„œ ì •ë³´ ê²€ìƒ‰ê³¼ ì¿¼ë¦¬ ì²˜ë¦¬ì˜ í•µì‹¬ ìš”ì†Œë¡œ ì‘ìš©í•˜ì—¬, ì‚¬ìš©ìì—ê²Œ ì •í™•í•˜ê³  ê´€ë ¨ì„± ë†’ì€ ë‹µë³€ì„ ì œê³µí•˜ëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ 3: Vector Store\n",
    "print(\"=\"*80)\n",
    "print(\"ì§ˆë¬¸ 3: Vector Storeì˜ ì—­í• \")\n",
    "print(\"=\"*80)\n",
    "\n",
    "answer3 = rag_chain.invoke(\"Vector StoreëŠ” RAG ì‹œìŠ¤í…œì—ì„œ ì–´ë–¤ ì—­í• ì„ í•˜ë‚˜ìš”?\")\n",
    "print(answer3)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "test4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ì§ˆë¬¸ 4: Embedding ëª¨ë¸ì˜ ì¤‘ìš”ì„±\n",
      "================================================================================\n",
      "Embedding ëª¨ë¸ì€ ì •ë³´ ê²€ìƒ‰ ë° ìì—°ì–´ ì²˜ë¦¬ì—ì„œ ë§¤ìš° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤. ê·¸ ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ì •ë³´ ê²€ìƒ‰ì˜ íš¨ìœ¨ì„±**: Embedding ëª¨ë¸ì€ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬, ìœ ì‚¬í•œ ì˜ë¯¸ë¥¼ ê°€ì§„ ë¬¸ì„œë‚˜ ë‹¨ì–´ë¥¼ ê°€ê¹Œìš´ ìœ„ì¹˜ì— ë°°ì¹˜í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê²€ìƒ‰ ì‹œ ìœ ì‚¬í•œ ë‚´ìš©ì„ ë¹ ë¥´ê²Œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ë‹¤ì–‘í•œ ë°ì´í„° ìœ í˜• ì§€ì›**: ë¬¸ì„œì˜ ë‹¤ì–‘í•œ í˜•ì‹(ì˜ˆ: í…ìŠ¤íŠ¸, í‘œ, ì´ë¯¸ì§€ ë“±)ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì´ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‹¤ì¤‘ ë²¡í„° ê²€ìƒ‰ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì™€ í‘œê°€ í˜¼í•©ëœ ë¬¸ì„œì—ì„œ ê° í‘œë¥¼ ì¶”ì¶œí•˜ê³  ìš”ì•½í•˜ì—¬ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **ëª¨ë¸ì˜ ì„±ëŠ¥ í–¥ìƒ**: ì ì ˆí•œ chunk sizeë¥¼ ì„ íƒí•¨ìœ¼ë¡œì¨ ë¬¸ì„œì˜ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë¡œë“œí•˜ê³ , LLMì˜ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°ì— ë§ê²Œ ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ê²€ìƒ‰ ì„±ëŠ¥ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "Embedding ëª¨ë¸ì„ ì„ íƒí•  ë•Œ ê³ ë ¤í•´ì•¼ í•  ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ë°ì´í„°ì˜ íŠ¹ì„±**: ë°ì´í„°ê°€ ì–´ë–¤ í˜•ì‹ì¸ì§€, ê·¸ë¦¬ê³  ì–´ë–¤ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³ ì í•˜ëŠ”ì§€ì— ë”°ë¼ ì í•©í•œ ëª¨ë¸ì„ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, í…ìŠ¤íŠ¸ê°€ ë§ì€ ê²½ìš° OpenAIì˜ `text-embedding-3-large` ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ë²¡í„° ìŠ¤í† ì–´ì˜ ì„ íƒ**: Embedding ëª¨ë¸ê³¼ í•¨ê»˜ ì‚¬ìš©í•  ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, In-memory VectorStore, FAISS, Milvus ë“± ë‹¤ì–‘í•œ ì˜µì…˜ì´ ìˆìœ¼ë©°, ë°ì´í„°ì˜ í¬ê¸°ì™€ ê²€ìƒ‰ ì†ë„ì— ë”°ë¼ ì í•©í•œ ìŠ¤í† ì–´ë¥¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ì¸ë±ì‹± ì „ëµ**: ë¬¸ì„œì˜ ì¸ë±ì‹± ë°©ë²•ë„ ì¤‘ìš”í•©ë‹ˆë‹¤. ë¬¸ì„œë¥¼ ì‘ì€ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì¸ë±ì‹±í•˜ë©´ ê²€ìƒ‰ íš¨ìœ¨ì´ ë†’ì•„ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, `Text Splitters`ë¥¼ ì‚¬ìš©í•˜ì—¬ í° ë¬¸ì„œë¥¼ ì‘ì€ ì²­í¬ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì´ ìœ ìš©í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ ìš”ì†Œë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ ê³ ë ¤í•˜ì—¬ ì í•©í•œ Embedding ëª¨ë¸ê³¼ ì¸ë±ì‹± ì „ëµì„ ì„ íƒí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ 4: Embedding ëª¨ë¸\n",
    "print(\"=\"*80)\n",
    "print(\"ì§ˆë¬¸ 4: Embedding ëª¨ë¸ì˜ ì¤‘ìš”ì„±\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "answer4 = rag_chain.invoke(\"Embedding ëª¨ë¸ì€ ì™œ ì¤‘ìš”í•˜ê³ , ì–´ë–»ê²Œ ì„ íƒí•´ì•¼ í•˜ë‚˜ìš”?\")\n",
    "print(answer4)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8b8f6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ì§ˆë¬¸ 5: langchainì˜ íŠ¹ì„±\n",
      "================================================================================\n",
      "Langchainì—ì„œëŠ” RAGë¥¼ ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„í•©ë‹ˆë‹¤:\n",
      "\n",
      "1. **ë¬¸ì„œ ì¸ë±ì‹± ë° ì €ì¥**: RAG ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•˜ê¸° ìœ„í•´ ë¨¼ì € ë¬¸ì„œë¥¼ ë¡œë“œí•˜ê³ , ì´ë¥¼ ì ì ˆíˆ ë¶„í• í•œ í›„, Vector Storeì— ì €ì¥í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì€ ë¬¸ì„œì˜ ê²€ìƒ‰ ê°€ëŠ¥ì„±ì„ ë†’ì´ëŠ” ë° í•„ìˆ˜ì ì…ë‹ˆë‹¤.\n",
      "\n",
      "2. **ê²€ìƒ‰ ë° ìƒì„±**: RAG ì—ì´ì „íŠ¸ëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³ , ê²€ìƒ‰ëœ ë¬¸ì„œì™€ ì´ˆê¸° ì§ˆë¬¸ì„ ëª¨ë¸ì— ì „ë‹¬í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ì€ ë‘ ê°€ì§€ ë°©ë²•ìœ¼ë¡œ êµ¬í˜„ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
      "   - **ë‹¨ìˆœ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” RAG ì—ì´ì „íŠ¸**: ì´ ë°©ë²•ì€ ì¼ë°˜ì ì¸ êµ¬í˜„ìœ¼ë¡œ, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\n",
      "   - **ë‘ ë‹¨ê³„ RAG ì²´ì¸**: ì´ ë°©ë²•ì€ ê° ì¿¼ë¦¬ì— ëŒ€í•´ ë‹¨ì¼ LLM í˜¸ì¶œë§Œì„ ì‚¬ìš©í•˜ì—¬ ë¹ ë¥´ê³  íš¨ê³¼ì ì¸ ì²˜ë¦¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **ì˜ˆì‹œ ì½”ë“œ**: RAG ì—ì´ì „íŠ¸ë¥¼ êµ¬ì„±í•˜ê¸° ìœ„í•´, ë‹¤ìŒê³¼ ê°™ì€ ê°„ë‹¨í•œ ë„êµ¬ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
      "   ```python\n",
      "   from langchain.tools import tool\n",
      "\n",
      "   @tool\n",
      "   def search_tool(query: str):\n",
      "       # Vector Storeì—ì„œ ì¿¼ë¦¬ì— ëŒ€í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ë¡œì§\n",
      "       pass\n",
      "   ```\n",
      "\n",
      "ì´ëŸ¬í•œ ë°©ì‹ìœ¼ë¡œ Langchainì€ RAG ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ íš¨ê³¼ì ìœ¼ë¡œ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ 5: langchainì˜ íŠ¹ì„±\n",
    "print(\"=\"*80)\n",
    "print(\"ì§ˆë¬¸ 5: langchainì˜ íŠ¹ì„±\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "answer5 = rag_chain.invoke(\"Langchainì—ì„œëŠ” RAGë¥¼ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„í•˜ë‚˜ìš”?\")\n",
    "print(answer5)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming",
   "metadata": {},
   "source": [
    "### 4-4. ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "test_streaming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸: RAG ì‹œìŠ¤í…œ êµ¬ì¶• ì‹œ ì£¼ì˜ì‚¬í•­\n",
      "================================================================================\n",
      "RAG ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ë•Œ ì£¼ì˜í•´ì•¼ í•  ì ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **Query Transformations**: ì‚¬ìš©ì ì…ë ¥ì˜ ë³€ë™ì„±ì— ê°•í•œ ê²€ìƒ‰ì„ ë§Œë“¤ê¸° ìœ„í•´ ì¿¼ë¦¬ ë³€í™˜ì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤. ì‚¬ìš©ì ì§ˆë¬¸ì´ ê²€ìƒ‰ ì‘ì—…ì— ì í•©í•˜ì§€ ì•Šê²Œ ì˜ëª» í‘œí˜„ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì¿¼ë¦¬ ë³€í™˜ ê¸°ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì…ë ¥ì„ ìˆ˜ì •í•˜ì—¬ ê²€ìƒ‰ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **Query Construction**: ë°ì´í„°ì— ì¿¼ë¦¬í•˜ê¸° ìœ„í•´ í•„ìš”í•œ êµ¬ë¬¸ì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤. ìì—°ì–´ë¡œ ëœ ì§ˆë¬¸ì€ ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤ë‚˜ ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ì™€ ê°™ì€ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ íŠ¹ì • êµ¬ë¬¸ìœ¼ë¡œ ë³€í™˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìì—°ì–´ ì§ˆë¬¸ì„ SQL ìš”ì²­ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” Text-to-SQL ê¸°ìˆ ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3. **Dynamic Query Routing**: ë‹¤ì–‘í•œ ë°ì´í„° ì €ì¥ì†Œë¥¼ í†µí•´ ë“¤ì–´ì˜¤ëŠ” ì¿¼ë¦¬ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë¼ìš°íŒ…í•˜ê¸° ìœ„í•´ LLMì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” RAG ì‹œìŠ¤í…œì˜ ìœ ì—°ì„±ì„ ë†’ì´ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.\n",
      "\n",
      "4. **Document Relevance Grading**: ë¬¸ì„œì˜ ê´€ë ¨ì„±ì„ í‰ê°€í•˜ê³  ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì¬ì‘ì„±í•˜ëŠ” ë‹¨ê³„ ì¶”ê°€ë¥¼ í†µí•´ ë” ê¹Šì€ ì œì–´ì™€ ì‚¬ìš©ì ë§ì¶¤í™”ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ ìš”ì†Œë“¤ì„ ê³ ë ¤í•˜ì—¬ RAG ì‹œìŠ¤í…œì„ ì„¤ê³„í•˜ë©´ ë³´ë‹¤ íš¨ê³¼ì ì´ê³  ì‚¬ìš©ì ì¹œí™”ì ì¸ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥\n",
    "print(\"=\"*80)\n",
    "print(\"ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸: RAG ì‹œìŠ¤í…œ êµ¬ì¶• ì‹œ ì£¼ì˜ì‚¬í•­\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "answer = rag_chain.stream(\"RAG ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ë•Œ ì£¼ì˜í•´ì•¼ í•  ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\")\n",
    "for chunk in answer:\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation",
   "metadata": {},
   "source": [
    "## 5. ê²°ê³¼ í‰ê°€ ë° ê°œì„ ì \n",
    "\n",
    "### í‰ê°€ ê¸°ì¤€:\n",
    "1. **ì •í™•ë„**: ë‹µë³€ì´ ë¬¸ë§¥ì— ê¸°ë°˜í•˜ê³  ìˆëŠ”ê°€?\n",
    "2. **ê´€ë ¨ì„±**: ì§ˆë¬¸ê³¼ ë‹µë³€ì´ ì¼ì¹˜í•˜ëŠ”ê°€?\n",
    "3. **ì™„ì „ì„±**: ì¶©ë¶„í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ”ê°€?\n",
    "4. **ëª…í™•ì„±**: ì´í•´í•˜ê¸° ì‰¬ìš´ ë‹µë³€ì¸ê°€?\n",
    "\n",
    "### ê°œì„  ë°©í–¥:\n",
    "- ë” ë‹¤ì–‘í•œ ë¬¸ì„œ ì†ŒìŠ¤ ì¶”ê°€\n",
    "- ì²­í¬ í¬ê¸° ìµœì í™”\n",
    "- ë‹¤ë¥¸ ì„ë² ë”© ëª¨ë¸ ì‹¤í—˜ (HuggingFace)\n",
    "- ê²€ìƒ‰ ê²°ê³¼ ìˆ˜(k) ì¡°ì •\n",
    "- í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í‚¤ì›Œë“œ + ì˜ë¯¸ ê¸°ë°˜)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## ğŸ“Š í”„ë¡œì íŠ¸ ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "- âœ… Milestone 1: ë¬¸ì„œ ìˆ˜ì§‘ ë° ë¡œë“œ (AI Agent & RAG ë¸”ë¡œê·¸ 5ê°œ)\n",
    "- âœ… Milestone 2: ì²­í‚¹ ì „ëµ ë¹„êµ (CharacterTextSplitter vs RecursiveCharacterTextSplitter)\n",
    "- âœ… Milestone 3: ì„ë² ë”© ë° ë²¡í„° ì €ì¥ (OpenAI Embeddings + FAISS)\n",
    "- âœ… Milestone 4: ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸ (4ê°œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸)\n",
    "\n",
    "### ì£¼ìš” ì„±ê³¼:\n",
    "- AI Agent & RAG ê´€ë ¨ ê²€ìƒ‰ ì‹œìŠ¤í…œ êµ¬ì¶• ì™„ë£Œ\n",
    "- 2ê°€ì§€ ì²­í‚¹ ë°©ë²• ë¹„êµ ë° ìµœì  ë°©ë²• ì„ ì •\n",
    "- FAISS ë²¡í„°ìŠ¤í† ì–´ë¥¼ í™œìš©í•œ íš¨ìœ¨ì ì¸ ê²€ìƒ‰\n",
    "- ì‹¤ìš©ì ì¸ ì§ˆë¬¸-ë‹µë³€ ì‹œìŠ¤í…œ êµ¬í˜„"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youngha-nKRCD7e9-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
