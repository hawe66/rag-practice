{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ffab601",
   "metadata": {},
   "source": [
    "# Week 5: LangGraph 인지 아키텍처 - 의도 분류 + 라우팅 시스템\n",
    "\n",
    "## 과제 개요\n",
    "- **주제**: 사용자 의도에 따라 다른 처리 경로로 분기하는 인지 아키텍처 설계\n",
    "- **목표**: Router 노드로 의도 분류 → 조건부 엣지로 라우팅 → 의도별 처리 노드 실행\n",
    "- **핵심**: LangGraph의 `add_conditional_edges`로 그래프 내에서 분기\n",
    "\n",
    "## 구현 구조\n",
    "```\n",
    "사용자 질문\n",
    "    ↓\n",
    "[Router] 의도 분류 (DOC_QA / SUMMARY / SMALL_TALK)\n",
    "    ↓\n",
    "┌─────────┬──────────┬─────────────┐\n",
    "│ DOC_QA  │ SUMMARY  │ SMALL_TALK  │\n",
    "│ (RAG)   │ (요약)    │ (잡담)       │\n",
    "└────┬────┴─────┬────┴──────┬──────┘\n",
    "     ↓          ↓           ↓\n",
    "   RAG 답변   요약 답변   일반 답변\n",
    "```\n",
    "\n",
    "## 마일스톤\n",
    "1. State 설계 + 문서 로드\n",
    "2. Router 노드 (의도 분류)\n",
    "3. 의도별 처리 노드 (DOC_QA, SUMMARY, SMALL_TALK)\n",
    "4. 조건부 분기 그래프 구성\n",
    "5. 3개 시나리오 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Cell 2: 라이브러리 Import\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 라이브러리 Import 완료\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Cell 2: 라이브러리 Import\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# 기본 라이브러리\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# LangChain Core\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# LangGraph (핵심!)\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from typing import TypedDict, Annotated, Literal\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "print(\"✅ 라이브러리 Import 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e53c56d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cell 3: API 키 로드 및 전역 설정\n",
      "================================================================================\n",
      "✅ OpenAI API 키 로드 완료\n",
      "✅ LLM: gpt-4o-mini\n",
      "✅ Embeddings: text-embedding-3-small\n",
      "✅ Text Splitter: SemanticChunker\n",
      "   - Breakpoint type: percentile\n",
      "   - Threshold: 95 (상위 5% 의미 변화 지점에서 분할)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n[Semantic Chunking 특징]\\n- 의미 기반 분할: 문장 간 유사도로 자동 분할\\n- 가변 청크 크기: 의미 단위에 따라 크기 조정\\n- 장점: 맥락 보존, 의미 단위 유지\\n- 단점: 처리 시간 증가 (임베딩 계산)\\n\\n[Breakpoint 유형]\\n- percentile: 상위 X% 유사도 차이에서 분할\\n- standard_deviation: 표준편차 기준 분할\\n- interquartile: 사분위수 기준 분할\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cell 3: API 키 로드 및 전역 설정\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# API 키 로드\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in .env file\")\n",
    "\n",
    "print(\"✅ OpenAI API 키 로드 완료\")\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# 전역 설정\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "# LLM\n",
    "LLM_MODEL = \"gpt-4o-mini\"\n",
    "LLM_TEMPERATURE = 0.2\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=LLM_MODEL,\n",
    "    temperature=LLM_TEMPERATURE,\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "# Embeddings\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    api_key=openai_api_key\n",
    ")\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# Text Splitter: Semantic Chunking\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=1000,\n",
    "#     chunk_overlap=200\n",
    "# )\n",
    "\n",
    "text_splitter = SemanticChunker(\n",
    "    embeddings=embeddings,\n",
    "    breakpoint_threshold_type=\"percentile\",  # \"percentile\", \"standard_deviation\", \"interquartile\"\n",
    "    breakpoint_threshold_amount=95  # 상위 5% 유사도 차이에서 분할\n",
    ")\n",
    "\n",
    "print(f\"✅ LLM: {LLM_MODEL}\")\n",
    "print(f\"✅ Embeddings: text-embedding-3-small\")\n",
    "print(f\"✅ Text Splitter: SemanticChunker\")\n",
    "print(f\"   - Breakpoint type: percentile\")\n",
    "print(f\"   - Threshold: 95 (상위 5% 의미 변화 지점에서 분할)\")\n",
    "\n",
    "'''\n",
    "[Semantic Chunking 특징]\n",
    "- 의미 기반 분할: 문장 간 유사도로 자동 분할\n",
    "- 가변 청크 크기: 의미 단위에 따라 크기 조정\n",
    "- 장점: 맥락 보존, 의미 단위 유지\n",
    "- 단점: 처리 시간 증가 (임베딩 계산)\n",
    "\n",
    "[Breakpoint 유형]\n",
    "- percentile: 상위 X% 유사도 차이에서 분할\n",
    "- standard_deviation: 표준편차 기준 분할\n",
    "- interquartile: 사분위수 기준 분할\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac509ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cell 4: 문서 URL 정의 (검증된 링크)\n",
      "================================================================================\n",
      "총 13개 문서 URL 정의 완료\n",
      "\n",
      "문서 카테고리:\n",
      "  ✅ LangChain RAG Tutorials: 4개\n",
      "  ✅ LangChain Concepts: 4개\n",
      "  ✅ LangGraph Tutorials: 3개\n",
      "  ✅ LangChain How-to: 2개\n",
      "  ─────────────────────────────────\n",
      "  총 13개 (모두 docs.langchain.com 통일)\n",
      "\n",
      "사용 시나리오:\n",
      "  - DOC_QA (기술 Q&A): 개념 + 구현 방법\n",
      "  - SUMMARY (요약): 튜토리얼 + 개념 문서\n",
      "  - SMALL_TALK (잡담): 문서 불필요\n",
      "\n",
      "주요 링크 검증:\n",
      "  ✓ rag_agent: https://docs.langchain.com/oss/python/langchain/rag\n",
      "  ✓ semantic_search: https://docs.langchain.com/oss/python/langchain/knowledge-base\n",
      "  ✓ sql_agent: https://docs.langchain.com/oss/python/langchain/sql-agent\n",
      "  ...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cell 4: 문서 URL 정의 (검증된 링크)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# 문서 구성 전략:\n",
    "# - API Reference: 함수 설명 (DOC_QA)\n",
    "# - Conceptual Docs: 개념 설명 (DOC_QA + SUMMARY)\n",
    "# - Tutorials: 구현 가이드 (SUMMARY)\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "document_urls = {\n",
    "    # ────────────────────────────────────────────────────────────\n",
    "    # LangChain RAG Tutorials - 4개\n",
    "    # ────────────────────────────────────────────────────────────\n",
    "    \"rag_agent\": \"https://docs.langchain.com/oss/python/langchain/rag\",\n",
    "    # ✅ 검증: RAG agent 구현 (Lilian Weng 블로그)\n",
    "    \n",
    "    \"semantic_search\": \"https://docs.langchain.com/oss/python/langchain/knowledge-base\",\n",
    "    # ✅ 검증: 시맨틱 검색 튜토리얼\n",
    "    \n",
    "    \"sql_agent\": \"https://docs.langchain.com/oss/python/langchain/sql-agent\",\n",
    "    # ✅ SQL Agent 구현\n",
    "    \n",
    "    \"agents_tutorial\": \"https://docs.langchain.com/oss/python/langchain/agents\",\n",
    "    # ✅ Agent 개념 및 구현\n",
    "    \n",
    "    # ────────────────────────────────────────────────────────────\n",
    "    # LangChain Concepts - 4개\n",
    "    # ────────────────────────────────────────────────────────────\n",
    "    \"component_architecture\": \"https://docs.langchain.com/oss/python/langchain/component-architecture\",\n",
    "    # ✅ 컴포넌트 아키텍처\n",
    "    \n",
    "    \"memory_concepts\": \"https://docs.langchain.com/oss/python/concepts/memory\",\n",
    "    # ✅ Memory 개념\n",
    "    \n",
    "    \"context_concepts\": \"https://docs.langchain.com/oss/python/concepts/context\",\n",
    "    # ✅ Context 관리\n",
    "    \n",
    "    \"retrieval_concepts\": \"https://docs.langchain.com/oss/python/langchain/retrieval\",\n",
    "    # ✅ Retrieval 개념\n",
    "    \n",
    "    # ────────────────────────────────────────────────────────────\n",
    "    # LangGraph Tutorials - 3개\n",
    "    # ────────────────────────────────────────────────────────────\n",
    "    \"langgraph_overview\": \"https://docs.langchain.com/oss/python/langgraph/overview\",\n",
    "    # ✅ LangGraph 개요\n",
    "    \n",
    "    \"langgraph_graph_api\": \"https://docs.langchain.com/oss/python/langgraph/graph-api\",\n",
    "    # ✅ Graph API\n",
    "    \n",
    "    \"langgraph_agentic_rag\": \"https://docs.langchain.com/oss/python/langgraph/agentic-rag\",\n",
    "    # ✅ Agentic RAG (라우팅 예제!)\n",
    "    \n",
    "    # ────────────────────────────────────────────────────────────\n",
    "    # LangChain How-to - 2개\n",
    "    # ────────────────────────────────────────────────────────────\n",
    "    \"streaming\": \"https://docs.langchain.com/oss/python/langchain/streaming\",\n",
    "    # ✅ Streaming 구현\n",
    "    \n",
    "    \"structured_output\": \"https://docs.langchain.com/oss/python/langchain/structured-output\",\n",
    "    # ✅ Structured Output\n",
    "}\n",
    "\n",
    "all_urls = list(document_urls.values())\n",
    "\n",
    "print(f\"총 {len(all_urls)}개 문서 URL 정의 완료\\n\")\n",
    "\n",
    "print(\"문서 카테고리:\")\n",
    "print(f\"  ✅ LangChain RAG Tutorials: 4개\")\n",
    "print(f\"  ✅ LangChain Concepts: 4개\")\n",
    "print(f\"  ✅ LangGraph Tutorials: 3개\")\n",
    "print(f\"  ✅ LangChain How-to: 2개\")\n",
    "print(f\"  ─────────────────────────────────\")\n",
    "print(f\"  총 13개 (모두 docs.langchain.com 통일)\")\n",
    "\n",
    "print(\"\\n사용 시나리오:\")\n",
    "print(\"  - DOC_QA (기술 Q&A): 개념 + 구현 방법\")\n",
    "print(\"  - SUMMARY (요약): 튜토리얼 + 개념 문서\")\n",
    "print(\"  - SMALL_TALK (잡담): 문서 불필요\")\n",
    "\n",
    "print(\"\\n주요 링크 검증:\")\n",
    "for name, url in list(document_urls.items())[:3]:\n",
    "    print(f\"  ✓ {name}: {url}\")\n",
    "print(\"  ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e29b65d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cell 5: 문서 로드\n",
      "================================================================================\n",
      "\n",
      "13개 URL에서 문서 로드 중...\n",
      "(WebBaseLoader 사용, 시간이 다소 걸릴 수 있습니다)\n",
      "\n",
      "✅ 총 13개 문서 로드 완료\n",
      "\n",
      "[샘플] 처음 3개 문서:\n",
      "\n",
      "문서 1:\n",
      "  - Source: https://docs.langchain.com/oss/python/langchain/rag\n",
      "  - Length: 30612 characters\n",
      "  - Preview: TutorialsLangChainBuild a RAG agent with LangChainCopy pageCopy page‚ÄãOverview\n",
      "One of the most powe...\n",
      "\n",
      "문서 2:\n",
      "  - Source: https://docs.langchain.com/oss/python/langchain/knowledge-base\n",
      "  - Length: 26461 characters\n",
      "  - Preview: TutorialsLangChainBuild a semantic search engine with LangChainCopy pageCopy page​Overview\n",
      "This tuto...\n",
      "\n",
      "문서 3:\n",
      "  - Source: https://docs.langchain.com/oss/python/langchain/sql-agent\n",
      "  - Length: 19320 characters\n",
      "  - Preview: TutorialsLangChainBuild a SQL agentCopy pageCopy page‚ÄãOverview\n",
      "In this tutorial, you will learn ho...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cell 5: 문서 로드\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n{len(all_urls)}개 URL에서 문서 로드 중...\")\n",
    "print(\"(WebBaseLoader 사용, 시간이 다소 걸릴 수 있습니다)\\n\")\n",
    "\n",
    "# WebBaseLoader로 문서 로드\n",
    "import bs4\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=all_urls,\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(id=\"content-area\")\n",
    "    )\n",
    ")\n",
    "# loader = WebBaseLoader(all_urls)\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"✅ 총 {len(docs)}개 문서 로드 완료\")\n",
    "\n",
    "# 문서별 정보 출력 (샘플)\n",
    "print(\"\\n[샘플] 처음 3개 문서:\")\n",
    "for i, doc in enumerate(docs[:3], 1):\n",
    "    print(f\"\\n문서 {i}:\")\n",
    "    print(f\"  - Source: {doc.metadata.get('source', 'N/A')}\")\n",
    "    print(f\"  - Length: {len(doc.page_content)} characters\")\n",
    "    print(f\"  - Preview: {doc.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aea0845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cell 6: 문서 청킹 (SemanticChunker)\n",
      "================================================================================\n",
      "의미 기반 청킹 진행 중...\n",
      "(임베딩 계산으로 인해 시간이 다소 걸릴 수 있습니다)\n",
      "\n",
      "✅ 총 66개 청크 생성 완료\n",
      "\n",
      "청킹 통계:\n",
      "  - 총 문서 수: 13개\n",
      "  - 총 청크 수: 66개\n",
      "  - 평균 청크 크기: 3439 characters\n",
      "  - 최소 청크 크기: 11 characters\n",
      "  - 최대 청크 크기: 18894 characters\n",
      "  - 청킹 방식: Semantic (의미 기반)\n",
      "\n",
      "청크 크기 분포:\n",
      "  0-500       :  12개 ██\n",
      "  500-1000    :   5개 █\n",
      "  1000-1500   :   8개 █\n",
      "  1500-2000   :   8개 █\n",
      "  2000+       :  33개 ██████\n",
      "\n",
      "[샘플] 첫 번째 청크:\n",
      "  - Source: https://docs.langchain.com/oss/python/langchain/rag\n",
      "  - Size: 269 characters\n",
      "  - Content: TutorialsLangChainBuild a RAG agent with LangChainCopy pageCopy page‚ÄãOverview\n",
      "One of the most powerful applications enabled by LLMs is sophisticated question-answering (Q&A) chatbots. These are applications that can answer questions about specific source information....\n",
      "\n",
      "[샘플] 두 번째 청크:\n",
      "  - Source: https://docs.langchain.com/oss/python/langchain/rag\n",
      "  - Size: 4571 characters\n",
      "  - Content: These applications use a technique known as Retrieval Augmented Generation, or RAG. This tutorial will show how to build a simple Q&A application over an unstructured text data source. We will demonstrate:\n",
      "\n",
      "A RAG agent that executes searches with a simple tool. This is a good general-purpose impleme...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cell 6: 문서 청킹 (SemanticChunker)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"의미 기반 청킹 진행 중...\")\n",
    "print(\"(임베딩 계산으로 인해 시간이 다소 걸릴 수 있습니다)\\n\")\n",
    "\n",
    "# 문서 청킹\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"✅ 총 {len(chunks)}개 청크 생성 완료\")\n",
    "\n",
    "# 청킹 통계\n",
    "chunk_sizes = [len(chunk.page_content) for chunk in chunks]\n",
    "total_chars = sum(chunk_sizes)\n",
    "avg_chunk_size = total_chars / len(chunks)\n",
    "min_chunk_size = min(chunk_sizes)\n",
    "max_chunk_size = max(chunk_sizes)\n",
    "\n",
    "print(f\"\\n청킹 통계:\")\n",
    "print(f\"  - 총 문서 수: {len(docs)}개\")\n",
    "print(f\"  - 총 청크 수: {len(chunks)}개\")\n",
    "print(f\"  - 평균 청크 크기: {avg_chunk_size:.0f} characters\")\n",
    "print(f\"  - 최소 청크 크기: {min_chunk_size} characters\")\n",
    "print(f\"  - 최대 청크 크기: {max_chunk_size} characters\")\n",
    "print(f\"  - 청킹 방식: Semantic (의미 기반)\")\n",
    "\n",
    "# 청크 크기 분포 (간단한 히스토그램)\n",
    "print(\"\\n청크 크기 분포:\")\n",
    "ranges = [\n",
    "    (0, 500, \"0-500\"),\n",
    "    (500, 1000, \"500-1000\"),\n",
    "    (1000, 1500, \"1000-1500\"),\n",
    "    (1500, 2000, \"1500-2000\"),\n",
    "    (2000, float('inf'), \"2000+\")\n",
    "]\n",
    "\n",
    "for min_size, max_size, label in ranges:\n",
    "    count = sum(1 for size in chunk_sizes if min_size <= size < max_size)\n",
    "    bar = \"█\" * (count // 5 if count > 0 else 0)\n",
    "    print(f\"  {label:12s}: {count:3d}개 {bar}\")\n",
    "\n",
    "# 샘플 청크\n",
    "print(f\"\\n[샘플] 첫 번째 청크:\")\n",
    "print(f\"  - Source: {chunks[0].metadata.get('source', 'N/A')}\")\n",
    "print(f\"  - Size: {len(chunks[0].page_content)} characters\")\n",
    "print(f\"  - Content: {chunks[0].page_content[:300]}...\")\n",
    "\n",
    "if len(chunks) > 1:\n",
    "    print(f\"\\n[샘플] 두 번째 청크:\")\n",
    "    print(f\"  - Source: {chunks[1].metadata.get('source', 'N/A')}\")\n",
    "    print(f\"  - Size: {len(chunks[1].page_content)} characters\")\n",
    "    print(f\"  - Content: {chunks[1].page_content[:300]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71b912fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[샘플] 24 번째 청크:\n",
      "  - Source: https://docs.langchain.com/oss/python/langchain/agents\n",
      "  - Size: 1760 characters\n",
      "  - Content: For information on implementing long-term memory that persists across sessions, see Long-term memory. ​Streaming\n",
      "We’ve seen how the agent can be called with invoke to get a final response. If the agent executes multiple steps, this may take a while. To show intermediate progress, we can stream back ...\n"
     ]
    }
   ],
   "source": [
    "# 샘플 청크\n",
    "sidx = 24\n",
    "print(f\"\\n[샘플] {sidx} 번째 청크:\")\n",
    "print(f\"  - Source: {chunks[sidx].metadata.get('source', 'N/A')}\")\n",
    "print(f\"  - Size: {len(chunks[sidx].page_content)} characters\")\n",
    "print(f\"  - Content: {chunks[sidx].page_content[:300]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1f9e3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cell 7: 벡터스토어 생성 (Chroma)\n",
      "================================================================================\n",
      "✅ Chroma 벡터스토어 생성 완료\n",
      "  - Collection: week5_langgraph_docs\n",
      "  - 총 벡터 수: 66개\n",
      "  - Embedding 모델: text-embedding-3-small\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cell 7: 벡터스토어 생성 (Chroma)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Chroma 벡터스토어 생성\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"week5_langgraph_docs\"\n",
    ")\n",
    "\n",
    "print(f\"✅ Chroma 벡터스토어 생성 완료\")\n",
    "print(f\"  - Collection: week5_langgraph_docs\")\n",
    "print(f\"  - 총 벡터 수: {len(chunks)}개\")\n",
    "print(f\"  - Embedding 모델: text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbabd06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cell 8: Retriever 생성\n",
      "================================================================================\n",
      "✅ Retriever 생성 완료\n",
      "  - Search type: similarity\n",
      "  - k: 4 (상위 4개 문서 검색)\n",
      "\n",
      "[테스트 검색] Query: 'What is RAG?'\n",
      "검색 결과: 4개 문서\n",
      "\n",
      "  Doc 1:\n",
      "    Source: https://docs.langchain.com/oss/python/langchain/retrieval...\n",
      "    Content: Advanced usageRetrievalCopy pageCopy pageLarge Language Models (LLMs) are powerful, but they have tw...\n",
      "\n",
      "  Doc 2:\n",
      "    Source: https://docs.langchain.com/oss/python/langchain/retrieval...\n",
      "    Content: These systems offer more flexibility than fixed pipelines while maintaining some control over execut...\n",
      "\n",
      "  Doc 3:\n",
      "    Source: https://docs.langchain.com/oss/python/langchain/rag...\n",
      "    Content: Interface: API reference for the base interface. This completes the Indexing portion of the pipeline...\n",
      "\n",
      "  Doc 4:\n",
      "    Source: https://docs.langchain.com/oss/python/langchain/rag...\n",
      "    Content: These applications use a technique known as Retrieval Augmented Generation, or RAG. This tutorial wi...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cell 8: Retriever 생성\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Retriever 생성\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 4}\n",
    ")\n",
    "\n",
    "print(\"✅ Retriever 생성 완료\")\n",
    "print(\"  - Search type: similarity\")\n",
    "print(\"  - k: 4 (상위 4개 문서 검색)\")\n",
    "\n",
    "# 테스트 검색\n",
    "test_query = \"What is RAG?\"\n",
    "test_results = retriever.invoke(test_query)\n",
    "\n",
    "print(f\"\\n[테스트 검색] Query: '{test_query}'\")\n",
    "print(f\"검색 결과: {len(test_results)}개 문서\")\n",
    "for i, doc in enumerate(test_results, 1):\n",
    "    print(f\"\\n  Doc {i}:\")\n",
    "    print(f\"    Source: {doc.metadata.get('source', 'N/A')[:60]}...\")\n",
    "    print(f\"    Content: {doc.page_content[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eda22009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "현재 상태:\n",
      "  - 문서 수: 13개\n",
      "  - 청크 수: 66개\n",
      "  - Retriever: Ready ✅\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"현재 상태:\")\n",
    "print(f\"  - 문서 수: {len(docs)}개\")\n",
    "print(f\"  - 청크 수: {len(chunks)}개\")\n",
    "print(f\"  - Retriever: Ready ✅\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153bd089",
   "metadata": {},
   "source": [
    "# Section 1: State 설계 및 Router 노드 (Milestone 2)\n",
    "---\n",
    "\n",
    "## 목표\n",
    "- ChatState 정의 (messages, query, intent, context)\n",
    "- Router 노드 구현 (LLM 기반 의도 분류)\n",
    "- 3가지 의도 분류: DOC_QA, SUMMARY, SMALL_TALK\n",
    "\n",
    "## 의도(Intent) 정의\n",
    "1. **DOC_QA**: 기술 문서 질문 → RAG 처리\n",
    "   - 예: \"RAG란 무엇인가요?\", \"Retriever 종류는?\"\n",
    "   \n",
    "2. **SUMMARY**: 요약 요청 → 요약 노드\n",
    "   - 예: \"이 문서 요약해줘\", \"핵심만 3개 뽑아줘\"\n",
    "   \n",
    "3. **SMALL_TALK**: 일반 대화 → RAG 없이 LLM만\n",
    "   - 예: \"안녕\", \"고마워\", \"너 뭐야?\"\n",
    "\n",
    "## Router 동작 원리사용자 질문\n",
    "↓\n",
    "[Router] LLM으로 의도 분류\n",
    "↓\n",
    "state[\"intent\"] = \"DOC_QA\" | \"SUMMARY\" | \"SMALL_TALK\"\n",
    "↓\n",
    "조건부 엣지로 분기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c74bcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Cell 11: 1.1 ChatState 정의\n",
      "================================================================================\n",
      "✅ ChatState 정의 완료\n",
      "\n",
      "State 필드 설명:\n",
      "  - messages: LangGraph의 add_messages로 자동 누적\n",
      "  - query: 사용자의 현재 질문 (Router가 분석)\n",
      "  - intent: Router가 분류한 의도 (3가지 중 하나)\n",
      "  - context: DOC_QA/SUMMARY 노드에서 검색한 문서 내용\n",
      "\n",
      "의도(Intent) 3가지:\n",
      "  1. DOC_QA: 기술 질문 → RAG 검색 + 답변\n",
      "  2. SUMMARY: 요약 요청 → 검색 + 요약\n",
      "  3. SMALL_TALK: 잡담 → LLM만 사용\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Cell 11: 1.1 ChatState 정의\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# ChatState 정의\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "    \"\"\"LangGraph 인지 아키텍처 State\n",
    "    \n",
    "    Attributes:\n",
    "        messages: 대화 메시지 리스트 (자동 누적)\n",
    "        query: 현재 사용자 질문\n",
    "        intent: 분류된 의도 (DOC_QA | SUMMARY | SMALL_TALK)\n",
    "        context: RAG 검색 결과 (문서 내용)\n",
    "    \"\"\"\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "    query: str\n",
    "    intent: str  # \"DOC_QA\" | \"SUMMARY\" | \"SMALL_TALK\"\n",
    "    context: str\n",
    "\n",
    "print(\"✅ ChatState 정의 완료\")\n",
    "\n",
    "print(\"\"\"\n",
    "State 필드 설명:\n",
    "  - messages: LangGraph의 add_messages로 자동 누적\n",
    "  - query: 사용자의 현재 질문 (Router가 분석)\n",
    "  - intent: Router가 분류한 의도 (3가지 중 하나)\n",
    "  - context: DOC_QA/SUMMARY 노드에서 검색한 문서 내용\n",
    "  \n",
    "의도(Intent) 3가지:\n",
    "  1. DOC_QA: 기술 질문 → RAG 검색 + 답변\n",
    "  2. SUMMARY: 요약 요청 → 검색 + 요약\n",
    "  3. SMALL_TALK: 잡담 → LLM만 사용\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "750f1f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cell 12: 1.2 의도 분류 프롬프트 설계\n",
      "================================================================================\n",
      "✅ 의도 분류 프롬프트 생성 완료\n",
      "\n",
      "[프롬프트 미리보기]\n",
      "당신은 사용자 질문의 의도를 분류하는 전문가입니다.\n",
      "\n",
      "사용자 질문을 분석하여 다음 3가지 의도 중 하나로 분류하세요:\n",
      "\n",
      "1. **DOC_QA**: 기술 문서에 대한 구체적인 질문\n",
      "   - 예시: \"RAG란 무엇인가요?\", \"Retriever 종류는?\", \"LangGraph에서 State란?\"\n",
      "   - 키워드: what, how, explain, 무엇, 어떻게, 설명\n",
      "\n",
      "2. **SUMMARY**: 문서 요약 또는 정리 요청\n",
      "   - 예시: \"이 문서 요약해줘\", \"핵심만 3개 뽑아줘\", \"간단히 정리해줘\"\n",
      "   - 키워드: 요약, 정리, summarize, 핵심, 간단히, 포인트\n",
      "\n",
      "3. **SMALL_TALK**: 일반 대화, 인사, 감사 표현\n",
      "   - 예시: \"안녕\", \"고마워\", \"너 뭐야?\", \"잘 지내?\"\n",
      "   - 키워드: 안녕, 감사, hello, thanks, hi\n",
      "\n",
      "중요: 반드시 \"DOC_QA\", \"SUMMARY\", \"SMALL_TALK\" 중 정확히 하나만 출력하세요.\n",
      "다...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cell 12: 1.2 의도 분류 프롬프트 설계\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# Router용 의도 분류 프롬프트\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "intent_classification_template = \"\"\"당신은 사용자 질문의 의도를 분류하는 전문가입니다.\n",
    "\n",
    "사용자 질문을 분석하여 다음 3가지 의도 중 하나로 분류하세요:\n",
    "\n",
    "1. **DOC_QA**: 기술 문서에 대한 구체적인 질문\n",
    "   - 예시: \"RAG란 무엇인가요?\", \"Retriever 종류는?\", \"LangGraph에서 State란?\"\n",
    "   - 키워드: what, how, explain, 무엇, 어떻게, 설명\n",
    "\n",
    "2. **SUMMARY**: 문서 요약 또는 정리 요청\n",
    "   - 예시: \"이 문서 요약해줘\", \"핵심만 3개 뽑아줘\", \"간단히 정리해줘\"\n",
    "   - 키워드: 요약, 정리, summarize, 핵심, 간단히, 포인트\n",
    "\n",
    "3. **SMALL_TALK**: 일반 대화, 인사, 감사 표현\n",
    "   - 예시: \"안녕\", \"고마워\", \"너 뭐야?\", \"잘 지내?\"\n",
    "   - 키워드: 안녕, 감사, hello, thanks, hi\n",
    "\n",
    "중요: 반드시 \"DOC_QA\", \"SUMMARY\", \"SMALL_TALK\" 중 정확히 하나만 출력하세요.\n",
    "다른 말은 일체 하지 마세요.\n",
    "\n",
    "사용자 질문: {query}\n",
    "\n",
    "의도:\"\"\"\n",
    "\n",
    "intent_prompt = PromptTemplate(\n",
    "    template=intent_classification_template,\n",
    "    input_variables=[\"query\"]\n",
    ")\n",
    "\n",
    "print(\"✅ 의도 분류 프롬프트 생성 완료\")\n",
    "\n",
    "# 프롬프트 테스트\n",
    "print(\"\\n[프롬프트 미리보기]\")\n",
    "test_query = \"RAG란 무엇인가요?\"\n",
    "print(intent_prompt.format(query=test_query)[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06422428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cell 13: 1.3 Router 노드 구현 (LLM 기반)\n",
      "================================================================================\n",
      "✅ 의도 분류 체인 생성 완료\n",
      "✅ Router 노드 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cell 13: 1.3 Router 노드 구현 (LLM 기반)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# 의도 분류 체인 생성\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "intent_chain = intent_prompt | llm | StrOutputParser()\n",
    "\n",
    "print(\"✅ 의도 분류 체인 생성 완료\")\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# Router 노드 함수\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "def router_node(state: ChatState) -> ChatState:\n",
    "    \"\"\"의도 분류 노드\n",
    "    \n",
    "    사용자 질문(query)을 분석하여 의도를 분류합니다.\n",
    "    \n",
    "    Args:\n",
    "        state: 현재 그래프 상태\n",
    "        \n",
    "    Returns:\n",
    "        업데이트된 상태 (intent 필드 추가)\n",
    "    \"\"\"\n",
    "    query = state[\"query\"]\n",
    "    \n",
    "    print(f\"\\n[Router] 질문 분석 중: '{query}'\")\n",
    "    \n",
    "    # LLM으로 의도 분류\n",
    "    raw_intent = intent_chain.invoke({\"query\": query})\n",
    "    \n",
    "    # 의도 정제 (공백 제거, 대문자 변환)\n",
    "    intent = raw_intent.strip().upper()\n",
    "    \n",
    "    # 유효성 검사\n",
    "    valid_intents = [\"DOC_QA\", \"SUMMARY\", \"SMALL_TALK\"]\n",
    "    if intent not in valid_intents:\n",
    "        # LLM이 잘못된 출력을 했을 경우 기본값 설정\n",
    "        print(f\"  ⚠️ 유효하지 않은 의도: '{intent}' → 기본값 'DOC_QA' 사용\")\n",
    "        intent = \"DOC_QA\"\n",
    "    \n",
    "    print(f\"  ✅ 분류된 의도: {intent}\")\n",
    "    \n",
    "    return {\"intent\": intent}\n",
    "\n",
    "print(\"✅ Router 노드 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "405ac5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cell 14: 1.4 Router 노드 테스트\n",
      "================================================================================\n",
      "총 9개 질문으로 Router 테스트\n",
      "\n",
      "\n",
      "[Router] 질문 분석 중: 'RAG란 무엇인가요?'\n",
      "  ✅ 분류된 의도: DOC_QA\n",
      "\n",
      "\n",
      "[Router] 질문 분석 중: 'LangGraph에서 State는 어떻게 사용하나요?'\n",
      "  ✅ 분류된 의도: DOC_QA\n",
      "\n",
      "\n",
      "[Router] 질문 분석 중: 'Retriever의 종류를 알려주세요'\n",
      "  ✅ 분류된 의도: DOC_QA\n",
      "\n",
      "\n",
      "[Router] 질문 분석 중: '이 문서를 요약해줘'\n",
      "  ✅ 분류된 의도: SUMMARY\n",
      "\n",
      "\n",
      "[Router] 질문 분석 중: '핵심 포인트 3개만 뽑아줘'\n",
      "  ✅ 분류된 의도: SUMMARY\n",
      "\n",
      "\n",
      "[Router] 질문 분석 중: '간단히 정리해주세요'\n",
      "  ✅ 분류된 의도: SUMMARY\n",
      "\n",
      "\n",
      "[Router] 질문 분석 중: '안녕하세요'\n",
      "  ✅ 분류된 의도: SMALL_TALK\n",
      "\n",
      "\n",
      "[Router] 질문 분석 중: '고마워요'\n",
      "  ✅ 분류된 의도: SMALL_TALK\n",
      "\n",
      "\n",
      "[Router] 질문 분석 중: '당신은 누구인가요?'\n",
      "  ✅ 분류된 의도: SMALL_TALK\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Router 테스트 결과 요약\n",
      "================================================================================\n",
      "\n",
      "의도별 분류 결과:\n",
      "  - DOC_QA: 3개\n",
      "  - SUMMARY: 3개\n",
      "  - SMALL_TALK: 3개\n",
      "\n",
      "상세 결과:\n",
      "--------------------------------------------------------------------------------\n",
      "질문                                       | 의도             \n",
      "--------------------------------------------------------------------------------\n",
      "RAG란 무엇인가요?                              | DOC_QA         \n",
      "LangGraph에서 State는 어떻게 사용하나요?            | DOC_QA         \n",
      "Retriever의 종류를 알려주세요                     | DOC_QA         \n",
      "이 문서를 요약해줘                               | SUMMARY        \n",
      "핵심 포인트 3개만 뽑아줘                           | SUMMARY        \n",
      "간단히 정리해주세요                               | SUMMARY        \n",
      "안녕하세요                                    | SMALL_TALK     \n",
      "고마워요                                     | SMALL_TALK     \n",
      "당신은 누구인가요?                               | SMALL_TALK     \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cell 14: 1.4 Router 노드 테스트\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# 테스트 질문들\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "test_questions = [\n",
    "    # DOC_QA 예상\n",
    "    \"RAG란 무엇인가요?\",\n",
    "    \"LangGraph에서 State는 어떻게 사용하나요?\",\n",
    "    \"Retriever의 종류를 알려주세요\",\n",
    "    \n",
    "    # SUMMARY 예상\n",
    "    \"이 문서를 요약해줘\",\n",
    "    \"핵심 포인트 3개만 뽑아줘\",\n",
    "    \"간단히 정리해주세요\",\n",
    "    \n",
    "    # SMALL_TALK 예상\n",
    "    \"안녕하세요\",\n",
    "    \"고마워요\",\n",
    "    \"당신은 누구인가요?\"\n",
    "]\n",
    "\n",
    "print(f\"총 {len(test_questions)}개 질문으로 Router 테스트\\n\")\n",
    "\n",
    "# 각 질문에 대해 의도 분류 테스트\n",
    "results = []\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    # State 구성\n",
    "    test_state = {\n",
    "        \"messages\": [],\n",
    "        \"query\": question,\n",
    "        \"intent\": \"\",\n",
    "        \"context\": \"\"\n",
    "    }\n",
    "    \n",
    "    # Router 실행\n",
    "    result = router_node(test_state)\n",
    "    intent = result[\"intent\"]\n",
    "    \n",
    "    results.append({\n",
    "        \"question\": question,\n",
    "        \"intent\": intent\n",
    "    })\n",
    "    \n",
    "    print()  # 줄바꿈\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# 결과 요약\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Router 테스트 결과 요약\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 의도별 카운트\n",
    "from collections import Counter\n",
    "intent_counts = Counter(r[\"intent\"] for r in results)\n",
    "\n",
    "print(\"\\n의도별 분류 결과:\")\n",
    "for intent, count in intent_counts.items():\n",
    "    print(f\"  - {intent}: {count}개\")\n",
    "\n",
    "# 상세 결과 표\n",
    "print(\"\\n상세 결과:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'질문':<40} | {'의도':<15}\")\n",
    "print(\"-\" * 80)\n",
    "for r in results:\n",
    "    print(f\"{r['question']:<40} | {r['intent']:<15}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbe7ec6",
   "metadata": {},
   "source": [
    "# Section 2: 의도별 처리 노드 (Milestone 3)\n",
    "---\n",
    "\n",
    "## 목표\n",
    "- 3가지 의도별 처리 노드 구현\n",
    "- 각 노드는 ChatState를 받아서 답변 생성\n",
    "\n",
    "## 노드 구조\n",
    "```\n",
    "1. DOC_QA 노드\n",
    "   - Retriever로 문서 검색\n",
    "   - 검색 결과 + 질문 → LLM\n",
    "   - 기술 문서 기반 답변\n",
    "\n",
    "2. SUMMARY 노드\n",
    "   - Retriever로 문서 검색\n",
    "   - 검색 결과를 요약\n",
    "   - 핵심 내용 추출\n",
    "\n",
    "3. SMALL_TALK 노드\n",
    "   - Retriever 사용 안 함\n",
    "   - LLM만으로 답변\n",
    "   - 일반 대화 처리\n",
    "```\n",
    "\n",
    "## 노드 출력\n",
    "- 모든 노드는 messages에 AIMessage 추가\n",
    "- DOC_QA/SUMMARY는 context도 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bf7ccee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Cell 17: 2.1 DOC_QA 노드 구현\n",
      "================================================================================\n",
      "✅ DOC_QA 노드 구현 완료\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Cell 17: 2.1 DOC_QA 노드 구현\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# DOC_QA용 프롬프트\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "doc_qa_template = \"\"\"당신은 LangChain/LangGraph 기술 문서 전문가입니다.\n",
    "\n",
    "제공된 문서를 기반으로 사용자 질문에 정확하게 답변하세요.\n",
    "\n",
    "규칙:\n",
    "- 문서에 있는 내용만 사용\n",
    "- 문서에 없으면 \"제공된 문서에 해당 정보가 없습니다\"\n",
    "- 간결하고 명확하게 답변\n",
    "- 필요시 예제 코드 포함\n",
    "\n",
    "검색된 문서:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변:\"\"\"\n",
    "\n",
    "doc_qa_prompt = PromptTemplate(\n",
    "    template=doc_qa_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# DOC_QA 노드 함수\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "def doc_qa_node(state: ChatState) -> ChatState:\n",
    "    \"\"\"DOC_QA 노드: 기술 문서 Q&A\n",
    "    \n",
    "    Retriever로 문서를 검색하고 LLM으로 답변 생성\n",
    "    \n",
    "    Args:\n",
    "        state: 현재 그래프 상태\n",
    "        \n",
    "    Returns:\n",
    "        업데이트된 상태 (messages, context)\n",
    "    \"\"\"\n",
    "    query = state[\"query\"]\n",
    "    \n",
    "    print(f\"\\n[DOC_QA] 질문: '{query}'\")\n",
    "    \n",
    "    # 1. 문서 검색\n",
    "    print(f\"  [1/3] Retriever로 문서 검색 중...\")\n",
    "    docs = retriever.invoke(query)\n",
    "    \n",
    "    # 검색된 문서 내용 합치기\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"[문서 {i+1}]\\n{doc.page_content}\" \n",
    "        for i, doc in enumerate(docs)\n",
    "    ])\n",
    "    \n",
    "    print(f\"  ✅ {len(docs)}개 문서 검색 완료\")\n",
    "    \n",
    "    # 2. LLM으로 답변 생성\n",
    "    print(f\"  [2/3] LLM으로 답변 생성 중...\")\n",
    "    \n",
    "    answer = (doc_qa_prompt | llm | StrOutputParser()).invoke({\n",
    "        \"context\": context,\n",
    "        \"question\": query\n",
    "    })\n",
    "    \n",
    "    print(f\"  ✅ 답변 생성 완료 ({len(answer)} characters)\")\n",
    "    \n",
    "    # 3. State 업데이트\n",
    "    print(f\"  [3/3] State 업데이트 중...\")\n",
    "    \n",
    "    # messages에 AI 답변 추가\n",
    "    ai_message = AIMessage(content=answer)\n",
    "    \n",
    "    print(f\"  ✅ DOC_QA 노드 완료\")\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [ai_message],\n",
    "        \"context\": context\n",
    "    }\n",
    "\n",
    "print(\"✅ DOC_QA 노드 구현 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07b24d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cell 18: 2.2 SUMMARY 노드 구현\n",
      "================================================================================\n",
      "✅ SUMMARY 노드 구현 완료\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cell 18: 2.2 SUMMARY 노드 구현\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# SUMMARY용 프롬프트\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "summary_template = \"\"\"당신은 기술 문서 요약 전문가입니다.\n",
    "\n",
    "제공된 문서를 분석하여 사용자가 요청한 방식으로 요약하세요.\n",
    "\n",
    "요약 규칙:\n",
    "- 핵심 내용만 간결하게\n",
    "- 사용자 요청 형식 준수 (예: \"3가지\", \"간단히\")\n",
    "- 불렛 포인트 또는 번호 사용\n",
    "- 기술 용어는 정확하게 유지\n",
    "\n",
    "검색된 문서:\n",
    "{context}\n",
    "\n",
    "사용자 요청: {question}\n",
    "\n",
    "요약:\"\"\"\n",
    "\n",
    "summary_prompt = PromptTemplate(\n",
    "    template=summary_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# SUMMARY 노드 함수\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "def summary_node(state: ChatState) -> ChatState:\n",
    "    \"\"\"SUMMARY 노드: 문서 요약\n",
    "    \n",
    "    Retriever로 문서를 검색하고 LLM으로 요약 생성\n",
    "    \n",
    "    Args:\n",
    "        state: 현재 그래프 상태\n",
    "        \n",
    "    Returns:\n",
    "        업데이트된 상태 (messages, context)\n",
    "    \"\"\"\n",
    "    query = state[\"query\"]\n",
    "    \n",
    "    print(f\"\\n[SUMMARY] 요청: '{query}'\")\n",
    "    \n",
    "    # 1. 문서 검색\n",
    "    print(f\"  [1/3] Retriever로 문서 검색 중...\")\n",
    "    docs = retriever.invoke(query)\n",
    "    \n",
    "    # 검색된 문서 내용 합치기\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"[문서 {i+1}]\\n{doc.page_content}\" \n",
    "        for i, doc in enumerate(docs)\n",
    "    ])\n",
    "    \n",
    "    print(f\"  ✅ {len(docs)}개 문서 검색 완료\")\n",
    "    \n",
    "    # 2. LLM으로 요약 생성\n",
    "    print(f\"  [2/3] LLM으로 요약 생성 중...\")\n",
    "    \n",
    "    summary = (summary_prompt | llm | StrOutputParser()).invoke({\n",
    "        \"context\": context,\n",
    "        \"question\": query\n",
    "    })\n",
    "    \n",
    "    print(f\"  ✅ 요약 생성 완료 ({len(summary)} characters)\")\n",
    "    \n",
    "    # 3. State 업데이트\n",
    "    print(f\"  [3/3] State 업데이트 중...\")\n",
    "    \n",
    "    # messages에 AI 답변 추가\n",
    "    ai_message = AIMessage(content=summary)\n",
    "    \n",
    "    print(f\"  ✅ SUMMARY 노드 완료\")\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [ai_message],\n",
    "        \"context\": context\n",
    "    }\n",
    "\n",
    "print(\"✅ SUMMARY 노드 구현 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e11714a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cell 19: 2.3 SMALL_TALK 노드 구현\n",
      "================================================================================\n",
      "✅ SMALL_TALK 노드 구현 완료\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cell 19: 2.3 SMALL_TALK 노드 구현\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# SMALL_TALK용 프롬프트\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "small_talk_template = \"\"\"당신은 친근한 AI 어시스턴트입니다.\n",
    "\n",
    "사용자와 자연스럽게 대화하세요.\n",
    "\n",
    "대화 규칙:\n",
    "- 친절하고 자연스럽게\n",
    "- 간결하게 답변\n",
    "- 필요시 LangChain/LangGraph 관련 도움 제안\n",
    "\n",
    "사용자: {question}\n",
    "\n",
    "답변:\"\"\"\n",
    "\n",
    "small_talk_prompt = PromptTemplate(\n",
    "    template=small_talk_template,\n",
    "    input_variables=[\"question\"]\n",
    ")\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# SMALL_TALK 노드 함수\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "def small_talk_node(state: ChatState) -> ChatState:\n",
    "    \"\"\"SMALL_TALK 노드: 일반 대화\n",
    "    \n",
    "    RAG 없이 LLM만으로 답변 생성\n",
    "    \n",
    "    Args:\n",
    "        state: 현재 그래프 상태\n",
    "        \n",
    "    Returns:\n",
    "        업데이트된 상태 (messages만)\n",
    "    \"\"\"\n",
    "    query = state[\"query\"]\n",
    "    \n",
    "    print(f\"\\n[SMALL_TALK] 대화: '{query}'\")\n",
    "    \n",
    "    # 1. LLM으로 답변 생성 (RAG 없음)\n",
    "    print(f\"  [1/2] LLM으로 답변 생성 중...\")\n",
    "    \n",
    "    answer = (small_talk_prompt | llm | StrOutputParser()).invoke({\n",
    "        \"question\": query\n",
    "    })\n",
    "    \n",
    "    print(f\"  ✅ 답변 생성 완료 ({len(answer)} characters)\")\n",
    "    \n",
    "    # 2. State 업데이트\n",
    "    print(f\"  [2/2] State 업데이트 중...\")\n",
    "    \n",
    "    # messages에 AI 답변 추가\n",
    "    ai_message = AIMessage(content=answer)\n",
    "    \n",
    "    print(f\"  ✅ SMALL_TALK 노드 완료\")\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [ai_message]\n",
    "    }\n",
    "\n",
    "print(\"✅ SMALL_TALK 노드 구현 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aeadbfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cell 20: 2.4 처리 노드 테스트\n",
      "================================================================================\n",
      "총 3개 노드 테스트\n",
      "\n",
      "================================================================================\n",
      "테스트 1/3: DOC_QA\n",
      "================================================================================\n",
      "\n",
      "[DOC_QA] 질문: 'RAG란 무엇인가요?'\n",
      "  [1/3] Retriever로 문서 검색 중...\n",
      "  ✅ 4개 문서 검색 완료\n",
      "  [2/3] LLM으로 답변 생성 중...\n",
      "  ✅ 답변 생성 완료 (317 characters)\n",
      "  [3/3] State 업데이트 중...\n",
      "  ✅ DOC_QA 노드 완료\n",
      "\n",
      "[결과]\n",
      "  - 답변 메시지: 1개\n",
      "  - 답변 내용: RAG는 Retrieval-Augmented Generation의 약자로, 대형 언어 모델(LLM)이 질문에 대한 답변을 생성할 때 외부 지식을 검색하여 통합하는 방법입니다. RAG는 LLM의 한계를 극복하기 위해 설계되었으며, 주로 두 가지 단계로 구성됩니다: \n",
      "\n",
      "1. **검색(Retrieve)**: 사용자의 입력에 대해 관련된 문서 조각을 검색합니다.\n",
      "...\n",
      "  - Context 길이: 12653 characters\n",
      "\n",
      "================================================================================\n",
      "테스트 2/3: SUMMARY\n",
      "================================================================================\n",
      "\n",
      "[SUMMARY] 요청: 'RAG 개념을 3가지로 요약해줘'\n",
      "  [1/3] Retriever로 문서 검색 중...\n",
      "  ✅ 4개 문서 검색 완료\n",
      "  [2/3] LLM으로 요약 생성 중...\n",
      "  ✅ 요약 생성 완료 (616 characters)\n",
      "  [3/3] State 업데이트 중...\n",
      "  ✅ SUMMARY 노드 완료\n",
      "\n",
      "[결과]\n",
      "  - 답변 메시지: 1개\n",
      "  - 답변 내용: 1. **Retrieval-Augmented Generation (RAG)**: LLMs enhance their responses by retrieving relevant external knowledge at query time, addressing limitations of finite context and static knowledge.\n",
      "\n",
      "2. **...\n",
      "  - Context 길이: 16955 characters\n",
      "\n",
      "================================================================================\n",
      "테스트 3/3: SMALL_TALK\n",
      "================================================================================\n",
      "\n",
      "[SMALL_TALK] 대화: '안녕하세요!'\n",
      "  [1/2] LLM으로 답변 생성 중...\n",
      "  ✅ 답변 생성 완료 (18 characters)\n",
      "  [2/2] State 업데이트 중...\n",
      "  ✅ SMALL_TALK 노드 완료\n",
      "\n",
      "[결과]\n",
      "  - 답변 메시지: 1개\n",
      "  - 답변 내용: 안녕하세요! 어떻게 도와드릴까요?...\n",
      "\n",
      "================================================================================\n",
      "✅ 모든 처리 노드 테스트 완료\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cell 20: 2.4 처리 노드 테스트\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# 각 노드별 테스트\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        \"intent\": \"DOC_QA\",\n",
    "        \"query\": \"RAG란 무엇인가요?\",\n",
    "        \"node\": doc_qa_node\n",
    "    },\n",
    "    {\n",
    "        \"intent\": \"SUMMARY\",\n",
    "        \"query\": \"RAG 개념을 3가지로 요약해줘\",\n",
    "        \"node\": summary_node\n",
    "    },\n",
    "    {\n",
    "        \"intent\": \"SMALL_TALK\",\n",
    "        \"query\": \"안녕하세요!\",\n",
    "        \"node\": small_talk_node\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"총 {len(test_cases)}개 노드 테스트\\n\")\n",
    "\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    print(\"=\"*80)\n",
    "    print(f\"테스트 {i}/{len(test_cases)}: {test_case['intent']}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # State 구성\n",
    "    test_state = {\n",
    "        \"messages\": [],\n",
    "        \"query\": test_case[\"query\"],\n",
    "        \"intent\": test_case[\"intent\"],\n",
    "        \"context\": \"\"\n",
    "    }\n",
    "    \n",
    "    # 노드 실행\n",
    "    result = test_case[\"node\"](test_state)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f\"\\n[결과]\")\n",
    "    print(f\"  - 답변 메시지: {len(result.get('messages', []))}개\")\n",
    "    if result.get(\"messages\"):\n",
    "        answer = result[\"messages\"][0].content\n",
    "        print(f\"  - 답변 내용: {answer[:200]}...\")\n",
    "    if result.get(\"context\"):\n",
    "        print(f\"  - Context 길이: {len(result['context'])} characters\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"✅ 모든 처리 노드 테스트 완료\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f808991",
   "metadata": {},
   "source": [
    "# Section 3: 조건부 분기 그래프 (Milestone 4)\n",
    "---\n",
    "\n",
    "## 목표\n",
    "- StateGraph로 인지 아키텍처 구성\n",
    "- add_conditional_edges로 의도별 라우팅\n",
    "- MemorySaver로 메모리 관리\n",
    "- 그래프 컴파일 및 시각화\n",
    "\n",
    "## 그래프 구조START\n",
    "↓  \n",
    "[Router] 의도 분류  \n",
    "↓  \n",
    "│ DOC_QA  │ SUMMARY  │ SMALL_TALK  │  \n",
    "↓          ↓           ↓  \n",
    "END        END         END  \n",
    "  \n",
    "## 핵심 요구사항 (과제 명시)  \n",
    "⚠️ **중요**: 조건부 분기는 반드시 add_conditional_edges 사용!  \n",
    "❌ 그래프 밖에서 if intent == ... 분기 금지  \n",
    "✅ 그래프 자체가 인지 아키텍처가 되어야 함  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef6b23f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Cell 23: 3.1 조건부 엣지 함수 정의\n",
      "================================================================================\n",
      "✅ 조건부 엣지 함수 정의 완료\n",
      "\n",
      "[조건부 엣지 함수 설명]\n",
      "- Router 노드가 설정한 state[\"intent\"]를 읽음\n",
      "- intent 값에 따라 다음 노드 이름 반환\n",
      "- 반환값: \"doc_qa\" | \"summary\" | \"small_talk\"\n",
      "- 이 함수는 add_conditional_edges에서 사용됨\n",
      "\n",
      "[중요!]\n",
      "  ❌ 금지: 그래프 밖에서 if intent == ... 분기\n",
      "  ✅ 필수: add_conditional_edges로 그래프 내 분기\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Cell 23: 3.1 조건부 엣지 함수 정의\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# 조건부 엣지 함수 (라우팅 로직)\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "def route_by_intent(state: ChatState) -> Literal[\"doc_qa\", \"summary\", \"small_talk\"]:\n",
    "    \"\"\"의도에 따라 다음 노드를 결정하는 라우팅 함수\n",
    "    \n",
    "    이 함수는 add_conditional_edges에서 사용됩니다.\n",
    "    Router 노드가 설정한 intent 값을 읽고 다음 노드를 결정합니다.\n",
    "    \n",
    "    Args:\n",
    "        state: 현재 그래프 상태\n",
    "        \n",
    "    Returns:\n",
    "        다음 노드 이름 (\"doc_qa\" | \"summary\" | \"small_talk\")\n",
    "    \"\"\"\n",
    "    intent = state.get(\"intent\", \"DOC_QA\")\n",
    "    \n",
    "    print(f\"\\n[Route] 현재 의도: {intent}\")\n",
    "    \n",
    "    # 의도에 따라 노드 이름 반환\n",
    "    if intent == \"DOC_QA\":\n",
    "        next_node = \"doc_qa\"\n",
    "    elif intent == \"SUMMARY\":\n",
    "        next_node = \"summary\"\n",
    "    elif intent == \"SMALL_TALK\":\n",
    "        next_node = \"small_talk\"\n",
    "    else:\n",
    "        # 기본값\n",
    "        print(f\"  ⚠️ 알 수 없는 의도: {intent} → 기본값 doc_qa 사용\")\n",
    "        next_node = \"doc_qa\"\n",
    "    \n",
    "    print(f\"  → 다음 노드: {next_node}\")\n",
    "    \n",
    "    return next_node\n",
    "\n",
    "print(\"✅ 조건부 엣지 함수 정의 완료\")\n",
    "\n",
    "print(\"\"\"\n",
    "[조건부 엣지 함수 설명]\n",
    "- Router 노드가 설정한 state[\"intent\"]를 읽음\n",
    "- intent 값에 따라 다음 노드 이름 반환\n",
    "- 반환값: \"doc_qa\" | \"summary\" | \"small_talk\"\n",
    "- 이 함수는 add_conditional_edges에서 사용됨\n",
    "\n",
    "[중요!]\n",
    "  ❌ 금지: 그래프 밖에서 if intent == ... 분기\n",
    "  ✅ 필수: add_conditional_edges로 그래프 내 분기\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76b03246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cell 24: 3.2 StateGraph 구성\n",
      "================================================================================\n",
      "\n",
      "[1/5] StateGraph 생성 중...\n",
      "  ✅ StateGraph 생성 완료\n",
      "\n",
      "[2/5] 노드 추가 중...\n",
      "  ✅ 'router' 노드 추가\n",
      "  ✅ 'doc_qa' 노드 추가\n",
      "  ✅ 'summary' 노드 추가\n",
      "  ✅ 'small_talk' 노드 추가\n",
      "\n",
      "[3/5] 엣지 추가 중...\n",
      "  ✅ START → router 엣지 추가\n",
      "\n",
      "[4/5] 조건부 엣지 추가 중...\n",
      "  ✅ router → (doc_qa | summary | small_talk) 조건부 엣지 추가\n",
      "\n",
      "[5/5] 처리 노드 → END 엣지 추가 중...\n",
      "  ✅ doc_qa → END 엣지 추가\n",
      "  ✅ summary → END 엣지 추가\n",
      "  ✅ small_talk → END 엣지 추가\n",
      "\n",
      "================================================================================\n",
      "✅ StateGraph 구성 완료\n",
      "================================================================================\n",
      "\n",
      "[그래프 구조]\n",
      "  START\n",
      "    ↓\n",
      "  router (의도 분류)\n",
      "    ↓\n",
      "  ┌─────────┬──────────┬─────────────┐\n",
      "  │ doc_qa  │ summary  │ small_talk  │\n",
      "  └────┬────┴─────┬────┴──────┬──────┘\n",
      "       ↓          ↓           ↓\n",
      "      END        END         END\n",
      "\n",
      "[조건부 엣지 동작]\n",
      "  1. router 노드가 state[\"intent\"] 설정\n",
      "  2. route_by_intent 함수가 intent 읽음\n",
      "  3. intent 값에 따라 다음 노드 결정\n",
      "  4. 자동으로 해당 노드로 이동\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cell 24: 3.2 StateGraph 구성\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# StateGraph 생성\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "print(\"\\n[1/5] StateGraph 생성 중...\")\n",
    "graph_builder = StateGraph(ChatState)\n",
    "print(\"  ✅ StateGraph 생성 완료\")\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# 노드 추가\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "print(\"\\n[2/5] 노드 추가 중...\")\n",
    "\n",
    "# Router 노드\n",
    "graph_builder.add_node(\"router\", router_node)\n",
    "print(\"  ✅ 'router' 노드 추가\")\n",
    "\n",
    "# DOC_QA 노드\n",
    "graph_builder.add_node(\"doc_qa\", doc_qa_node)\n",
    "print(\"  ✅ 'doc_qa' 노드 추가\")\n",
    "\n",
    "# SUMMARY 노드\n",
    "graph_builder.add_node(\"summary\", summary_node)\n",
    "print(\"  ✅ 'summary' 노드 추가\")\n",
    "\n",
    "# SMALL_TALK 노드\n",
    "graph_builder.add_node(\"small_talk\", small_talk_node)\n",
    "print(\"  ✅ 'small_talk' 노드 추가\")\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# 엣지 추가\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "print(\"\\n[3/5] 엣지 추가 중...\")\n",
    "\n",
    "# START → router\n",
    "graph_builder.add_edge(START, \"router\")\n",
    "print(\"  ✅ START → router 엣지 추가\")\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# 조건부 엣지 추가 (핵심!)\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "print(\"\\n[4/5] 조건부 엣지 추가 중...\")\n",
    "\n",
    "# router → (doc_qa | summary | small_talk)\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"router\",              # 출발 노드\n",
    "    route_by_intent,       # 라우팅 함수\n",
    "    {\n",
    "        \"doc_qa\": \"doc_qa\",         # route_by_intent가 \"doc_qa\" 반환 시\n",
    "        \"summary\": \"summary\",       # route_by_intent가 \"summary\" 반환 시\n",
    "        \"small_talk\": \"small_talk\"  # route_by_intent가 \"small_talk\" 반환 시\n",
    "    }\n",
    ")\n",
    "print(\"  ✅ router → (doc_qa | summary | small_talk) 조건부 엣지 추가\")\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# 처리 노드 → END\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "print(\"\\n[5/5] 처리 노드 → END 엣지 추가 중...\")\n",
    "\n",
    "graph_builder.add_edge(\"doc_qa\", END)\n",
    "print(\"  ✅ doc_qa → END 엣지 추가\")\n",
    "\n",
    "graph_builder.add_edge(\"summary\", END)\n",
    "print(\"  ✅ summary → END 엣지 추가\")\n",
    "\n",
    "graph_builder.add_edge(\"small_talk\", END)\n",
    "print(\"  ✅ small_talk → END 엣지 추가\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✅ StateGraph 구성 완료\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "[그래프 구조]\n",
    "  START\n",
    "    ↓\n",
    "  router (의도 분류)\n",
    "    ↓\n",
    "  ┌─────────┬──────────┬─────────────┐\n",
    "  │ doc_qa  │ summary  │ small_talk  │\n",
    "  └────┬────┴─────┬────┴──────┬──────┘\n",
    "       ↓          ↓           ↓\n",
    "      END        END         END\n",
    "\n",
    "[조건부 엣지 동작]\n",
    "  1. router 노드가 state[\"intent\"] 설정\n",
    "  2. route_by_intent 함수가 intent 읽음\n",
    "  3. intent 값에 따라 다음 노드 결정\n",
    "  4. 자동으로 해당 노드로 이동\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7aed2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cell 25: 3.3 MemorySaver 추가 및 컴파일\n",
      "================================================================================\n",
      "\n",
      "[1/2] MemorySaver 생성 중...\n",
      "  ✅ MemorySaver 생성 완료 (인메모리)\n",
      "\n",
      "[2/2] 그래프 컴파일 중...\n",
      "  ✅ 그래프 컴파일 완료\n",
      "\n",
      "================================================================================\n",
      "✅ LangGraph 인지 아키텍처 준비 완료\n",
      "================================================================================\n",
      "\n",
      "[컴파일된 그래프 정보]\n",
      "  - StateGraph: ChatState 기반\n",
      "  - Checkpointer: MemorySaver (인메모리)\n",
      "  - 노드 수: 4개 (router, doc_qa, summary, small_talk)\n",
      "  - 엣지: 일반 엣지 4개 + 조건부 엣지 1개\n",
      "\n",
      "[MemorySaver 특징]\n",
      "  ✅ 인메모리 저장 (빠름)\n",
      "  ✅ thread_id로 세션 구분\n",
      "  ✅ 대화 상태 자동 저장\n",
      "  ⚠️ 프로세스 종료 시 삭제 (테스트용)\n",
      "\n",
      "[프로덕션 환경]\n",
      "  - SqliteSaver: 로컬 DB 저장\n",
      "  - PostgresSaver: 프로덕션 DB 저장\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cell 25: 3.3 MemorySaver 추가 및 컴파일\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# MemorySaver 생성\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "print(\"\\n[1/2] MemorySaver 생성 중...\")\n",
    "memory_saver = MemorySaver()\n",
    "print(\"  ✅ MemorySaver 생성 완료 (인메모리)\")\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# 그래프 컴파일\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "print(\"\\n[2/2] 그래프 컴파일 중...\")\n",
    "app = graph_builder.compile(checkpointer=memory_saver)\n",
    "print(\"  ✅ 그래프 컴파일 완료\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✅ LangGraph 인지 아키텍처 준비 완료\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "[컴파일된 그래프 정보]\n",
    "  - StateGraph: ChatState 기반\n",
    "  - Checkpointer: MemorySaver (인메모리)\n",
    "  - 노드 수: 4개 (router, doc_qa, summary, small_talk)\n",
    "  - 엣지: 일반 엣지 4개 + 조건부 엣지 1개\n",
    "\n",
    "[MemorySaver 특징]\n",
    "  ✅ 인메모리 저장 (빠름)\n",
    "  ✅ thread_id로 세션 구분\n",
    "  ✅ 대화 상태 자동 저장\n",
    "  ⚠️ 프로세스 종료 시 삭제 (테스트용)\n",
    "  \n",
    "[프로덕션 환경]\n",
    "  - SqliteSaver: 로컬 DB 저장\n",
    "  - PostgresSaver: 프로덕션 DB 저장\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abb8a49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cell 26: 3.4 그래프 시각화 (선택)\n",
      "================================================================================\n",
      "\n",
      "[1/2] Mermaid 다이어그램 생성 중...\n",
      "  ✅ 다이어그램 생성 완료\n",
      "\n",
      "[2/2] 그래프 시각화:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 그래프 시각화 완료\n",
      "\n",
      "[그래프 구조 설명]\n",
      "  1. START: 그래프 시작점\n",
      "  2. router: 사용자 질문을 분석하여 intent 설정\n",
      "  3. 조건부 엣지: intent 값에 따라 분기\n",
      "     - DOC_QA → doc_qa 노드\n",
      "     - SUMMARY → summary 노드\n",
      "     - SMALL_TALK → small_talk 노드\n",
      "  4. 처리 노드: 각각 답변 생성\n",
      "  5. END: 그래프 종료\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cell 26: 3.4 그래프 시각화 (선택)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    # Mermaid 다이어그램 생성\n",
    "    print(\"\\n[1/2] Mermaid 다이어그램 생성 중...\")\n",
    "    \n",
    "    from IPython.display import Image, display\n",
    "    \n",
    "    # 그래프를 이미지로 변환\n",
    "    graph_image = app.get_graph().draw_mermaid_png()\n",
    "    \n",
    "    print(\"  ✅ 다이어그램 생성 완료\")\n",
    "    \n",
    "    # 이미지 표시\n",
    "    print(\"\\n[2/2] 그래프 시각화:\")\n",
    "    display(Image(graph_image))\n",
    "    \n",
    "    print(\"\\n✅ 그래프 시각화 완료\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n⚠️ 그래프 시각화 실패: {e}\")\n",
    "    print(\"\\n대신 텍스트로 그래프 구조 출력:\")\n",
    "    print(\"\"\"\n",
    "    ┌─────────┐\n",
    "    │  START  │\n",
    "    └────┬────┘\n",
    "         ↓\n",
    "    ┌────────────┐\n",
    "    │   router   │ (의도 분류)\n",
    "    └────┬───────┘\n",
    "         ↓ (조건부 엣지)\n",
    "    ┌────┴────┬─────────┬──────────────┐\n",
    "    │ doc_qa  │ summary │ small_talk   │\n",
    "    └────┬────┴────┬────┴──────┬───────┘\n",
    "         ↓         ↓           ↓\n",
    "    ┌────────────────────────────────┐\n",
    "    │            END                 │\n",
    "    └────────────────────────────────┘\n",
    "    \"\"\")\n",
    "\n",
    "print(\"\"\"\n",
    "[그래프 구조 설명]\n",
    "  1. START: 그래프 시작점\n",
    "  2. router: 사용자 질문을 분석하여 intent 설정\n",
    "  3. 조건부 엣지: intent 값에 따라 분기\n",
    "     - DOC_QA → doc_qa 노드\n",
    "     - SUMMARY → summary 노드\n",
    "     - SMALL_TALK → small_talk 노드\n",
    "  4. 처리 노드: 각각 답변 생성\n",
    "  5. END: 그래프 종료\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67db90fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cell 27: 3.5 단일 턴 테스트\n",
      "================================================================================\n",
      "총 3개 질문 테스트\n",
      "\n",
      "================================================================================\n",
      "테스트 1/3: 'RAG란 무엇인가요?'\n",
      "================================================================================\n",
      "\n",
      "[그래프 실행 중...]\n",
      "\n",
      "[Router] 질문 분석 중: 'RAG란 무엇인가요?'\n",
      "  ✅ 분류된 의도: DOC_QA\n",
      "\n",
      "[Route] 현재 의도: DOC_QA\n",
      "  → 다음 노드: doc_qa\n",
      "\n",
      "[DOC_QA] 질문: 'RAG란 무엇인가요?'\n",
      "  [1/3] Retriever로 문서 검색 중...\n",
      "  ✅ 4개 문서 검색 완료\n",
      "  [2/3] LLM으로 답변 생성 중...\n",
      "  ✅ 답변 생성 완료 (401 characters)\n",
      "  [3/3] State 업데이트 중...\n",
      "  ✅ DOC_QA 노드 완료\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "[실행 결과]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "  분류된 의도: DOC_QA\n",
      "  답변: RAG는 Retrieval-Augmented Generation의 약자로, 대형 언어 모델(LLM)이 질문에 대한 답변을 생성할 때 외부 지식을 검색하여 통합하는 방법입니다. RAG는 두 가지 주요 단계를 포함합니다: \n",
      "\n",
      "1. **검색(Retrieve)**: 사용자 입력에 따라 관련 문서를 검색합니다.\n",
      "2. **생성(Generate)**: 검색된 데이터를 ...\n",
      "  Context 사용: ✅ (12653 chars)\n",
      "\n",
      "================================================================================\n",
      "테스트 2/3: 'LangGraph 개념을 요약해줘'\n",
      "================================================================================\n",
      "\n",
      "[그래프 실행 중...]\n",
      "\n",
      "[Router] 질문 분석 중: 'LangGraph 개념을 요약해줘'\n",
      "  ✅ 분류된 의도: SUMMARY\n",
      "\n",
      "[Route] 현재 의도: SUMMARY\n",
      "  → 다음 노드: summary\n",
      "\n",
      "[SUMMARY] 요청: 'LangGraph 개념을 요약해줘'\n",
      "  [1/3] Retriever로 문서 검색 중...\n",
      "  ✅ 4개 문서 검색 완료\n",
      "  [2/3] LLM으로 요약 생성 중...\n",
      "  ✅ 요약 생성 완료 (504 characters)\n",
      "  [3/3] State 업데이트 중...\n",
      "  ✅ SUMMARY 노드 완료\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "[실행 결과]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "  분류된 의도: SUMMARY\n",
      "  답변: LangGraph 개념 요약:\n",
      "\n",
      "1. **기본 구조**:\n",
      "   - LangGraph는 에이전트 워크플로우를 그래프로 모델링.\n",
      "   - **State**: 현재 애플리케이션의 스냅샷을 나타내는 공유 데이터 구조.\n",
      "   - **Nodes**: 에이전트의 로직을 인코딩하는 함수.\n",
      "   - **Edges**: 현재 상태에 따라 다음 실행할 노드를 결정하는 함수.\n",
      "...\n",
      "  Context 사용: ✅ (12177 chars)\n",
      "\n",
      "================================================================================\n",
      "테스트 3/3: '안녕하세요!'\n",
      "================================================================================\n",
      "\n",
      "[그래프 실행 중...]\n",
      "\n",
      "[Router] 질문 분석 중: '안녕하세요!'\n",
      "  ✅ 분류된 의도: SMALL_TALK\n",
      "\n",
      "[Route] 현재 의도: SMALL_TALK\n",
      "  → 다음 노드: small_talk\n",
      "\n",
      "[SMALL_TALK] 대화: '안녕하세요!'\n",
      "  [1/2] LLM으로 답변 생성 중...\n",
      "  ✅ 답변 생성 완료 (18 characters)\n",
      "  [2/2] State 업데이트 중...\n",
      "  ✅ SMALL_TALK 노드 완료\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "[실행 결과]\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "  분류된 의도: SMALL_TALK\n",
      "  답변: 안녕하세요! 어떻게 도와드릴까요?...\n",
      "  Context 사용: ❌\n",
      "\n",
      "================================================================================\n",
      "✅ 단일 턴 테스트 완료\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cell 27: 3.5 단일 턴 테스트\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# 테스트 설정\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "# thread_id 설정 (세션 구분)\n",
    "config = {\"configurable\": {\"thread_id\": \"test-session-1\"}}\n",
    "\n",
    "test_questions = [\n",
    "    \"RAG란 무엇인가요?\",           # DOC_QA 예상\n",
    "    \"LangGraph 개념을 요약해줘\",    # SUMMARY 예상\n",
    "    \"안녕하세요!\",                 # SMALL_TALK 예상\n",
    "]\n",
    "\n",
    "print(f\"총 {len(test_questions)}개 질문 테스트\\n\")\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# 각 질문 실행\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(\"=\"*80)\n",
    "    print(f\"테스트 {i}/{len(test_questions)}: '{question}'\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 초기 상태 구성\n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=question)],\n",
    "        \"query\": question,\n",
    "        \"intent\": \"\",\n",
    "        \"context\": \"\"\n",
    "    }\n",
    "    \n",
    "    # 그래프 실행\n",
    "    print(\"\\n[그래프 실행 중...]\")\n",
    "    result = app.invoke(initial_state, config=config)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(\"\\n\" + \"─\"*80)\n",
    "    print(\"[실행 결과]\")\n",
    "    print(\"─\"*80)\n",
    "    print(f\"  분류된 의도: {result['intent']}\")\n",
    "    print(f\"  답변: {result['messages'][-1].content[:200]}...\")\n",
    "    if result.get('context'):\n",
    "        print(f\"  Context 사용: ✅ ({len(result['context'])} chars)\")\n",
    "    else:\n",
    "        print(f\"  Context 사용: ❌\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"✅ 단일 턴 테스트 완료\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c773aa",
   "metadata": {},
   "source": [
    "# Section 4: 멀티턴 대화 및 시나리오 테스트 (Milestone 5)\n",
    "---\n",
    "\n",
    "## 목표\n",
    "- 3개 시나리오 설계 및 실행\n",
    "- 멀티턴 대화 테스트\n",
    "- 메모리 동작 확인\n",
    "- 의도 분류 정확도 평가\n",
    "\n",
    "## 테스트 시나리오 (과제 요구사항)\n",
    "\n",
    "### 시나리오 1: DOC_QA 위주\n",
    "- 기술 문서 질문 연속\n",
    "- Follow-up 질문\n",
    "- 비교 요청\n",
    "\n",
    "### 시나리오 2: SUMMARY 위주\n",
    "- 문서 요약 요청\n",
    "- 추가 요약 요청\n",
    "- 세부 질문\n",
    "\n",
    "### 시나리오 3: Mixed (혼합)\n",
    "- 인사 (SMALL_TALK)\n",
    "- 기술 질문 (DOC_QA)\n",
    "- 요약 요청 (SUMMARY)\n",
    "- 감사 인사 (SMALL_TALK)\n",
    "\n",
    "## 평가 항목\n",
    "- 의도 분류 정확도\n",
    "- 라우팅 성공 여부\n",
    "- 답변 품질\n",
    "- 메모리 유지 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2fbe890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Cell 30: 4.1 시나리오 설계\n",
      "================================================================================\n",
      "총 3개 시나리오 정의 완료\n",
      "\n",
      "\n",
      "시나리오 1: DOC_QA 위주\n",
      "  설명: 기술 문서에 대한 연속 질문\n",
      "  턴 수: 4턴\n",
      "  예상 의도:\n",
      "    Turn 1: DOC_QA\n",
      "    Turn 2: DOC_QA\n",
      "    Turn 3: DOC_QA\n",
      "    Turn 4: DOC_QA\n",
      "\n",
      "시나리오 2: SUMMARY 위주\n",
      "  설명: 문서 요약 및 정리 요청\n",
      "  턴 수: 4턴\n",
      "  예상 의도:\n",
      "    Turn 1: SUMMARY\n",
      "    Turn 2: SUMMARY\n",
      "    Turn 3: SUMMARY\n",
      "    Turn 4: DOC_QA\n",
      "\n",
      "시나리오 3: Mixed (혼합)\n",
      "  설명: 다양한 의도가 섞인 자연스러운 대화\n",
      "  턴 수: 5턴\n",
      "  예상 의도:\n",
      "    Turn 1: SMALL_TALK\n",
      "    Turn 2: DOC_QA\n",
      "    Turn 3: SUMMARY\n",
      "    Turn 4: DOC_QA\n",
      "    Turn 5: SMALL_TALK\n",
      "\n",
      "================================================================================\n",
      "✅ 시나리오 설계 완료\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"Cell 30: 4.1 시나리오 설계\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# 3개 시나리오 정의\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "scenarios = {\n",
    "    \"시나리오 1: DOC_QA 위주\": {\n",
    "        \"description\": \"기술 문서에 대한 연속 질문\",\n",
    "        \"turns\": [\n",
    "            {\"query\": \"RAG란 무엇인가요?\", \"expected_intent\": \"DOC_QA\"},\n",
    "            {\"query\": \"그것은 어떻게 작동하나요?\", \"expected_intent\": \"DOC_QA\"},\n",
    "            {\"query\": \"Retriever의 종류는 무엇이 있나요?\", \"expected_intent\": \"DOC_QA\"},\n",
    "            {\"query\": \"LangGraph와 LangChain의 차이점은?\", \"expected_intent\": \"DOC_QA\"},\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"시나리오 2: SUMMARY 위주\": {\n",
    "        \"description\": \"문서 요약 및 정리 요청\",\n",
    "        \"turns\": [\n",
    "            {\"query\": \"RAG 개념을 요약해주세요\", \"expected_intent\": \"SUMMARY\"},\n",
    "            {\"query\": \"핵심 포인트 3개만 뽑아줘\", \"expected_intent\": \"SUMMARY\"},\n",
    "            {\"query\": \"더 간단하게 정리해주세요\", \"expected_intent\": \"SUMMARY\"},\n",
    "            {\"query\": \"첫 번째 포인트를 자세히 설명해줘\", \"expected_intent\": \"DOC_QA\"},\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"시나리오 3: Mixed (혼합)\": {\n",
    "        \"description\": \"다양한 의도가 섞인 자연스러운 대화\",\n",
    "        \"turns\": [\n",
    "            {\"query\": \"안녕하세요!\", \"expected_intent\": \"SMALL_TALK\"},\n",
    "            {\"query\": \"LangGraph에 대해 알려주세요\", \"expected_intent\": \"DOC_QA\"},\n",
    "            {\"query\": \"방금 설명한 내용을 요약해줘\", \"expected_intent\": \"SUMMARY\"},\n",
    "            {\"query\": \"State는 어떻게 사용하나요?\", \"expected_intent\": \"DOC_QA\"},\n",
    "            {\"query\": \"도움 주셔서 감사합니다!\", \"expected_intent\": \"SMALL_TALK\"},\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"총 {len(scenarios)}개 시나리오 정의 완료\\n\")\n",
    "\n",
    "for name, scenario in scenarios.items():\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"  설명: {scenario['description']}\")\n",
    "    print(f\"  턴 수: {len(scenario['turns'])}턴\")\n",
    "    print(f\"  예상 의도:\")\n",
    "    for i, turn in enumerate(scenario['turns'], 1):\n",
    "        print(f\"    Turn {i}: {turn['expected_intent']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✅ 시나리오 설계 완료\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8254d2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cell 31: 4.2 시나리오 실행 함수\n",
      "================================================================================\n",
      "✅ 시나리오 실행 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cell 31: 4.2 시나리오 실행 함수\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def run_scenario(scenario_name: str, scenario_data: dict, thread_id: str):\n",
    "    \"\"\"시나리오 실행 함수\n",
    "    \n",
    "    Args:\n",
    "        scenario_name: 시나리오 이름\n",
    "        scenario_data: 시나리오 데이터 (turns 리스트)\n",
    "        thread_id: 세션 ID\n",
    "        \n",
    "    Returns:\n",
    "        실행 결과 리스트\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"시나리오 실행: {scenario_name}\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"설명: {scenario_data['description']}\")\n",
    "    print(f\"턴 수: {len(scenario_data['turns'])}턴\")\n",
    "    print(f\"Thread ID: {thread_id}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    results = []\n",
    "    \n",
    "    for i, turn in enumerate(scenario_data['turns'], 1):\n",
    "        query = turn['query']\n",
    "        expected_intent = turn['expected_intent']\n",
    "        \n",
    "        print(f\"\\n{'─'*80}\")\n",
    "        print(f\"Turn {i}/{len(scenario_data['turns'])}\")\n",
    "        print(f\"{'─'*80}\")\n",
    "        print(f\"질문: {query}\")\n",
    "        print(f\"예상 의도: {expected_intent}\")\n",
    "        \n",
    "        # 초기 상태 구성\n",
    "        initial_state = {\n",
    "            \"messages\": [HumanMessage(content=query)],\n",
    "            \"query\": query,\n",
    "            \"intent\": \"\",\n",
    "            \"context\": \"\"\n",
    "        }\n",
    "        \n",
    "        # 그래프 실행\n",
    "        try:\n",
    "            result = app.invoke(initial_state, config=config)\n",
    "            \n",
    "            actual_intent = result['intent']\n",
    "            answer = result['messages'][-1].content\n",
    "            \n",
    "            # 의도 일치 여부\n",
    "            intent_match = actual_intent == expected_intent\n",
    "            \n",
    "            print(f\"\\n[결과]\")\n",
    "            print(f\"  실제 의도: {actual_intent}\")\n",
    "            print(f\"  의도 일치: {'✅' if intent_match else '❌'}\")\n",
    "            print(f\"  답변 길이: {len(answer)} characters\")\n",
    "            print(f\"  답변 미리보기: {answer[:150]}...\")\n",
    "            \n",
    "            # 결과 저장\n",
    "            results.append({\n",
    "                \"turn\": i,\n",
    "                \"query\": query,\n",
    "                \"expected_intent\": expected_intent,\n",
    "                \"actual_intent\": actual_intent,\n",
    "                \"intent_match\": intent_match,\n",
    "                \"answer\": answer,\n",
    "                \"context_used\": bool(result.get('context'))\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ 오류 발생: {e}\")\n",
    "            results.append({\n",
    "                \"turn\": i,\n",
    "                \"query\": query,\n",
    "                \"expected_intent\": expected_intent,\n",
    "                \"actual_intent\": \"ERROR\",\n",
    "                \"intent_match\": False,\n",
    "                \"answer\": \"\",\n",
    "                \"context_used\": False\n",
    "            })\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"✅ {scenario_name} 완료\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"✅ 시나리오 실행 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68b733ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cell 32: 4.3 시나리오 1 실행 (DOC_QA 위주)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "시나리오 실행: 시나리오 1: DOC_QA 위주\n",
      "================================================================================\n",
      "설명: 기술 문서에 대한 연속 질문\n",
      "턴 수: 4턴\n",
      "Thread ID: scenario-1-doc-qa\n",
      "================================================================================\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Turn 1/4\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "질문: RAG란 무엇인가요?\n",
      "예상 의도: DOC_QA\n",
      "\n",
      "[Router] 질문 분석 중: 'RAG란 무엇인가요?'\n",
      "  ✅ 분류된 의도: DOC_QA\n",
      "\n",
      "[Route] 현재 의도: DOC_QA\n",
      "  → 다음 노드: doc_qa\n",
      "\n",
      "[DOC_QA] 질문: 'RAG란 무엇인가요?'\n",
      "  [1/3] Retriever로 문서 검색 중...\n",
      "  ✅ 4개 문서 검색 완료\n",
      "  [2/3] LLM으로 답변 생성 중...\n",
      "  ✅ 답변 생성 완료 (287 characters)\n",
      "  [3/3] State 업데이트 중...\n",
      "  ✅ DOC_QA 노드 완료\n",
      "\n",
      "[결과]\n",
      "  실제 의도: DOC_QA\n",
      "  의도 일치: ✅\n",
      "  답변 길이: 287 characters\n",
      "  답변 미리보기: RAG는 Retrieval-Augmented Generation의 약자로, 대형 언어 모델(LLM)이 질문에 대한 답변을 생성할 때 외부 지식을 검색하여 통합하는 방법론입니다. RAG는 두 가지 주요 단계로 구성됩니다: \n",
      "\n",
      "1. **검색(Retrieve)**: 사용자 ...\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Turn 2/4\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "질문: 그것은 어떻게 작동하나요?\n",
      "예상 의도: DOC_QA\n",
      "\n",
      "[Router] 질문 분석 중: '그것은 어떻게 작동하나요?'\n",
      "  ✅ 분류된 의도: DOC_QA\n",
      "\n",
      "[Route] 현재 의도: DOC_QA\n",
      "  → 다음 노드: doc_qa\n",
      "\n",
      "[DOC_QA] 질문: '그것은 어떻게 작동하나요?'\n",
      "  [1/3] Retriever로 문서 검색 중...\n",
      "  ✅ 4개 문서 검색 완료\n",
      "  [2/3] LLM으로 답변 생성 중...\n",
      "  ✅ 답변 생성 완료 (20 characters)\n",
      "  [3/3] State 업데이트 중...\n",
      "  ✅ DOC_QA 노드 완료\n",
      "\n",
      "[결과]\n",
      "  실제 의도: DOC_QA\n",
      "  의도 일치: ✅\n",
      "  답변 길이: 20 characters\n",
      "  답변 미리보기: 제공된 문서에 해당 정보가 없습니다....\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Turn 3/4\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "질문: Retriever의 종류는 무엇이 있나요?\n",
      "예상 의도: DOC_QA\n",
      "\n",
      "[Router] 질문 분석 중: 'Retriever의 종류는 무엇이 있나요?'\n",
      "  ✅ 분류된 의도: DOC_QA\n",
      "\n",
      "[Route] 현재 의도: DOC_QA\n",
      "  → 다음 노드: doc_qa\n",
      "\n",
      "[DOC_QA] 질문: 'Retriever의 종류는 무엇이 있나요?'\n",
      "  [1/3] Retriever로 문서 검색 중...\n",
      "  ✅ 4개 문서 검색 완료\n",
      "  [2/3] LLM으로 답변 생성 중...\n",
      "  ✅ 답변 생성 완료 (233 characters)\n",
      "  [3/3] State 업데이트 중...\n",
      "  ✅ DOC_QA 노드 완료\n",
      "\n",
      "[결과]\n",
      "  실제 의도: DOC_QA\n",
      "  의도 일치: ✅\n",
      "  답변 길이: 233 characters\n",
      "  답변 미리보기: Retriever의 종류로는 다음과 같은 것들이 있습니다:\n",
      "\n",
      "1. **VectorStoreRetriever**: VectorStore에서 생성된 Retriever로, 기본적으로 \"similarity\" 검색 유형을 사용하며, \"mmr\" (maximum marginal r...\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Turn 4/4\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "질문: LangGraph와 LangChain의 차이점은?\n",
      "예상 의도: DOC_QA\n",
      "\n",
      "[Router] 질문 분석 중: 'LangGraph와 LangChain의 차이점은?'\n",
      "  ✅ 분류된 의도: DOC_QA\n",
      "\n",
      "[Route] 현재 의도: DOC_QA\n",
      "  → 다음 노드: doc_qa\n",
      "\n",
      "[DOC_QA] 질문: 'LangGraph와 LangChain의 차이점은?'\n",
      "  [1/3] Retriever로 문서 검색 중...\n",
      "  ✅ 4개 문서 검색 완료\n",
      "  [2/3] LLM으로 답변 생성 중...\n",
      "  ✅ 답변 생성 완료 (258 characters)\n",
      "  [3/3] State 업데이트 중...\n",
      "  ✅ DOC_QA 노드 완료\n",
      "\n",
      "[결과]\n",
      "  실제 의도: DOC_QA\n",
      "  의도 일치: ✅\n",
      "  답변 길이: 258 characters\n",
      "  답변 미리보기: LangGraph는 저수준의 오케스트레이션 프레임워크로, 장기 실행 및 상태 유지 에이전트를 구축, 관리 및 배포하는 데 중점을 둡니다. 반면, LangChain은 에이전트 아키텍처를 제공하는 고수준의 추상화로, 모델 및 도구와의 통합을 지원합니다. LangGraph는...\n",
      "\n",
      "================================================================================\n",
      "✅ 시나리오 1: DOC_QA 위주 완료\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "시나리오 1 결과 분석\n",
      "================================================================================\n",
      "\n",
      "의도 분류 정확도: 4/4 (100.0%)\n",
      "\n",
      "턴별 결과:\n",
      "--------------------------------------------------------------------------------\n",
      "Turn   | 예상           | 실제           | 일치    \n",
      "--------------------------------------------------------------------------------\n",
      "1      | DOC_QA       | DOC_QA       | ✅     \n",
      "2      | DOC_QA       | DOC_QA       | ✅     \n",
      "3      | DOC_QA       | DOC_QA       | ✅     \n",
      "4      | DOC_QA       | DOC_QA       | ✅     \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "특징:\n",
      "  - 모든 질문이 DOC_QA 예상\n",
      "  - Follow-up 질문 포함 (Turn 2: '그것은...')\n",
      "  - Context 사용: 4/4턴\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cell 32: 4.3 시나리오 1 실행 (DOC_QA 위주)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "scenario_1_results = run_scenario(\n",
    "    \"시나리오 1: DOC_QA 위주\",\n",
    "    scenarios[\"시나리오 1: DOC_QA 위주\"],\n",
    "    thread_id=\"scenario-1-doc-qa\"\n",
    ")\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# 결과 분석\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"시나리오 1 결과 분석\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "total_turns = len(scenario_1_results)\n",
    "correct_intents = sum(1 for r in scenario_1_results if r['intent_match'])\n",
    "accuracy = (correct_intents / total_turns * 100) if total_turns > 0 else 0\n",
    "\n",
    "print(f\"\\n의도 분류 정확도: {correct_intents}/{total_turns} ({accuracy:.1f}%)\")\n",
    "\n",
    "print(\"\\n턴별 결과:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Turn':<6} | {'예상':<12} | {'실제':<12} | {'일치':<6}\")\n",
    "print(\"-\" * 80)\n",
    "for r in scenario_1_results:\n",
    "    match_symbol = \"✅\" if r['intent_match'] else \"❌\"\n",
    "    print(f\"{r['turn']:<6} | {r['expected_intent']:<12} | {r['actual_intent']:<12} | {match_symbol:<6}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\n특징:\")\n",
    "print(f\"  - 모든 질문이 DOC_QA 예상\")\n",
    "print(f\"  - Follow-up 질문 포함 (Turn 2: '그것은...')\")\n",
    "print(f\"  - Context 사용: {sum(1 for r in scenario_1_results if r['context_used'])}/{total_turns}턴\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b5646ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cell 33: 4.4 시나리오 2 실행 (SUMMARY 위주)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "시나리오 실행: 시나리오 2: SUMMARY 위주\n",
      "================================================================================\n",
      "설명: 문서 요약 및 정리 요청\n",
      "턴 수: 4턴\n",
      "Thread ID: scenario-2-summary\n",
      "================================================================================\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Turn 1/4\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "질문: RAG 개념을 요약해주세요\n",
      "예상 의도: SUMMARY\n",
      "\n",
      "[Router] 질문 분석 중: 'RAG 개념을 요약해주세요'\n",
      "  ✅ 분류된 의도: SUMMARY\n",
      "\n",
      "[Route] 현재 의도: SUMMARY\n",
      "  → 다음 노드: summary\n",
      "\n",
      "[SUMMARY] 요청: 'RAG 개념을 요약해주세요'\n",
      "  [1/3] Retriever로 문서 검색 중...\n",
      "  ✅ 4개 문서 검색 완료\n",
      "  [2/3] LLM으로 요약 생성 중...\n",
      "  ✅ 요약 생성 완료 (500 characters)\n",
      "  [3/3] State 업데이트 중...\n",
      "  ✅ SUMMARY 노드 완료\n",
      "\n",
      "[결과]\n",
      "  실제 의도: SUMMARY\n",
      "  의도 일치: ✅\n",
      "  답변 길이: 500 characters\n",
      "  답변 미리보기: RAG(검색 증강 생성)의 개념 요약:\n",
      "\n",
      "1. **정의**: RAG는 LLM이 외부 지식을 검색하여 답변을 생성하는 방식으로, LLM의 한계를 극복하기 위해 설계됨.\n",
      "   \n",
      "2. **구성 요소**:\n",
      "   - **문서 로더**: 외부 데이터 소스에서 데이터를 가져옴.\n",
      " ...\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Turn 2/4\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "질문: 핵심 포인트 3개만 뽑아줘\n",
      "예상 의도: SUMMARY\n",
      "\n",
      "[Router] 질문 분석 중: '핵심 포인트 3개만 뽑아줘'\n",
      "  ✅ 분류된 의도: SUMMARY\n",
      "\n",
      "[Route] 현재 의도: SUMMARY\n",
      "  → 다음 노드: summary\n",
      "\n",
      "[SUMMARY] 요청: '핵심 포인트 3개만 뽑아줘'\n",
      "  [1/3] Retriever로 문서 검색 중...\n",
      "  ✅ 4개 문서 검색 완료\n",
      "  [2/3] LLM으로 요약 생성 중...\n",
      "  ✅ 요약 생성 완료 (194 characters)\n",
      "  [3/3] State 업데이트 중...\n",
      "  ✅ SUMMARY 노드 완료\n",
      "\n",
      "[결과]\n",
      "  실제 의도: SUMMARY\n",
      "  의도 일치: ✅\n",
      "  답변 길이: 194 characters\n",
      "  답변 미리보기: 1. **NIKE, Inc. 설립 연도**: NIKE는 1967년에 오리건주 법률에 따라 설립됨.\n",
      "2. **2023년 매출**: NIKE의 2023년 매출은 512억 달러로, 전년 대비 10% 증가.\n",
      "3. **총 이익률 감소**: 2023년 총 이익률은 43.5%로, ...\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Turn 3/4\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "질문: 더 간단하게 정리해주세요\n",
      "예상 의도: SUMMARY\n",
      "\n",
      "[Router] 질문 분석 중: '더 간단하게 정리해주세요'\n",
      "  ✅ 분류된 의도: SUMMARY\n",
      "\n",
      "[Route] 현재 의도: SUMMARY\n",
      "  → 다음 노드: summary\n",
      "\n",
      "[SUMMARY] 요청: '더 간단하게 정리해주세요'\n",
      "  [1/3] Retriever로 문서 검색 중...\n",
      "  ✅ 4개 문서 검색 완료\n",
      "  [2/3] LLM으로 요약 생성 중...\n",
      "  ✅ 요약 생성 완료 (340 characters)\n",
      "  [3/3] State 업데이트 중...\n",
      "  ✅ SUMMARY 노드 완료\n",
      "\n",
      "[결과]\n",
      "  실제 의도: SUMMARY\n",
      "  의도 일치: ✅\n",
      "  답변 길이: 340 characters\n",
      "  답변 미리보기: 1. **에러 처리 방식**:\n",
      "   - 기본값: 모든 에러를 기본 메시지로 처리.\n",
      "   - 사용자 정의 메시지: `handle_errors`에 문자열을 지정하여 고정 메시지로 재시도.\n",
      "   - 특정 예외 처리: 특정 예외 타입에 대해서만 재시도.\n",
      "\n",
      "2. **모델 생성 ...\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Turn 4/4\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "질문: 첫 번째 포인트를 자세히 설명해줘\n",
      "예상 의도: DOC_QA\n",
      "\n",
      "[Router] 질문 분석 중: '첫 번째 포인트를 자세히 설명해줘'\n",
      "  ✅ 분류된 의도: DOC_QA\n",
      "\n",
      "[Route] 현재 의도: DOC_QA\n",
      "  → 다음 노드: doc_qa\n",
      "\n",
      "[DOC_QA] 질문: '첫 번째 포인트를 자세히 설명해줘'\n",
      "  [1/3] Retriever로 문서 검색 중...\n",
      "  ✅ 4개 문서 검색 완료\n",
      "  [2/3] LLM으로 답변 생성 중...\n",
      "  ✅ 답변 생성 완료 (20 characters)\n",
      "  [3/3] State 업데이트 중...\n",
      "  ✅ DOC_QA 노드 완료\n",
      "\n",
      "[결과]\n",
      "  실제 의도: DOC_QA\n",
      "  의도 일치: ✅\n",
      "  답변 길이: 20 characters\n",
      "  답변 미리보기: 제공된 문서에 해당 정보가 없습니다....\n",
      "\n",
      "================================================================================\n",
      "✅ 시나리오 2: SUMMARY 위주 완료\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "시나리오 2 결과 분석\n",
      "================================================================================\n",
      "\n",
      "의도 분류 정확도: 4/4 (100.0%)\n",
      "\n",
      "턴별 결과:\n",
      "--------------------------------------------------------------------------------\n",
      "Turn   | 예상           | 실제           | 일치    \n",
      "--------------------------------------------------------------------------------\n",
      "1      | SUMMARY      | SUMMARY      | ✅     \n",
      "2      | SUMMARY      | SUMMARY      | ✅     \n",
      "3      | SUMMARY      | SUMMARY      | ✅     \n",
      "4      | DOC_QA       | DOC_QA       | ✅     \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "특징:\n",
      "  - Turn 1-3: SUMMARY (요약 요청)\n",
      "  - Turn 4: DOC_QA (세부 설명 요청)\n",
      "  - 의도 전환 테스트\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cell 33: 4.4 시나리오 2 실행 (SUMMARY 위주)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "scenario_2_results = run_scenario(\n",
    "    \"시나리오 2: SUMMARY 위주\",\n",
    "    scenarios[\"시나리오 2: SUMMARY 위주\"],\n",
    "    thread_id=\"scenario-2-summary\"\n",
    ")\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# 결과 분석\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"시나리오 2 결과 분석\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "total_turns = len(scenario_2_results)\n",
    "correct_intents = sum(1 for r in scenario_2_results if r['intent_match'])\n",
    "accuracy = (correct_intents / total_turns * 100) if total_turns > 0 else 0\n",
    "\n",
    "print(f\"\\n의도 분류 정확도: {correct_intents}/{total_turns} ({accuracy:.1f}%)\")\n",
    "\n",
    "print(\"\\n턴별 결과:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Turn':<6} | {'예상':<12} | {'실제':<12} | {'일치':<6}\")\n",
    "print(\"-\" * 80)\n",
    "for r in scenario_2_results:\n",
    "    match_symbol = \"✅\" if r['intent_match'] else \"❌\"\n",
    "    print(f\"{r['turn']:<6} | {r['expected_intent']:<12} | {r['actual_intent']:<12} | {match_symbol:<6}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\n특징:\")\n",
    "print(f\"  - Turn 1-3: SUMMARY (요약 요청)\")\n",
    "print(f\"  - Turn 4: DOC_QA (세부 설명 요청)\")\n",
    "print(f\"  - 의도 전환 테스트\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77ed34cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cell 34: 4.5 시나리오 3 실행 (Mixed)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "시나리오 실행: 시나리오 3: Mixed (혼합)\n",
      "================================================================================\n",
      "설명: 다양한 의도가 섞인 자연스러운 대화\n",
      "턴 수: 5턴\n",
      "Thread ID: scenario-3-mixed\n",
      "================================================================================\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Turn 1/5\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "질문: 안녕하세요!\n",
      "예상 의도: SMALL_TALK\n",
      "\n",
      "[Router] 질문 분석 중: '안녕하세요!'\n",
      "  ✅ 분류된 의도: SMALL_TALK\n",
      "\n",
      "[Route] 현재 의도: SMALL_TALK\n",
      "  → 다음 노드: small_talk\n",
      "\n",
      "[SMALL_TALK] 대화: '안녕하세요!'\n",
      "  [1/2] LLM으로 답변 생성 중...\n",
      "  ✅ 답변 생성 완료 (18 characters)\n",
      "  [2/2] State 업데이트 중...\n",
      "  ✅ SMALL_TALK 노드 완료\n",
      "\n",
      "[결과]\n",
      "  실제 의도: SMALL_TALK\n",
      "  의도 일치: ✅\n",
      "  답변 길이: 18 characters\n",
      "  답변 미리보기: 안녕하세요! 어떻게 도와드릴까요?...\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Turn 2/5\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "질문: LangGraph에 대해 알려주세요\n",
      "예상 의도: DOC_QA\n",
      "\n",
      "[Router] 질문 분석 중: 'LangGraph에 대해 알려주세요'\n",
      "  ✅ 분류된 의도: DOC_QA\n",
      "\n",
      "[Route] 현재 의도: DOC_QA\n",
      "  → 다음 노드: doc_qa\n",
      "\n",
      "[DOC_QA] 질문: 'LangGraph에 대해 알려주세요'\n",
      "  [1/3] Retriever로 문서 검색 중...\n",
      "  ✅ 4개 문서 검색 완료\n",
      "  [2/3] LLM으로 답변 생성 중...\n",
      "  ✅ 답변 생성 완료 (547 characters)\n",
      "  [3/3] State 업데이트 중...\n",
      "  ✅ DOC_QA 노드 완료\n",
      "\n",
      "[결과]\n",
      "  실제 의도: DOC_QA\n",
      "  의도 일치: ✅\n",
      "  답변 길이: 547 characters\n",
      "  답변 미리보기: LangGraph는 복잡한 작업을 처리하는 에이전트를 설계하기 위한 저수준 오케스트레이션 프레임워크이자 런타임입니다. LangGraph는 장기 실행되고 상태를 유지하는 에이전트를 구축, 관리 및 배포하는 데 중점을 두고 있으며, 내구성 있는 실행, 스트리밍, 인간 개입...\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Turn 3/5\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "질문: 방금 설명한 내용을 요약해줘\n",
      "예상 의도: SUMMARY\n",
      "\n",
      "[Router] 질문 분석 중: '방금 설명한 내용을 요약해줘'\n",
      "  ✅ 분류된 의도: SUMMARY\n",
      "\n",
      "[Route] 현재 의도: SUMMARY\n",
      "  → 다음 노드: summary\n",
      "\n",
      "[SUMMARY] 요청: '방금 설명한 내용을 요약해줘'\n",
      "  [1/3] Retriever로 문서 검색 중...\n",
      "  ✅ 4개 문서 검색 완료\n",
      "  [2/3] LLM으로 요약 생성 중...\n",
      "  ✅ 요약 생성 완료 (375 characters)\n",
      "  [3/3] State 업데이트 중...\n",
      "  ✅ SUMMARY 노드 완료\n",
      "\n",
      "[결과]\n",
      "  실제 의도: SUMMARY\n",
      "  의도 일치: ✅\n",
      "  답변 길이: 375 characters\n",
      "  답변 미리보기: 1. **NIKE, Inc. 개요**:\n",
      "   - 1967년 오리건주에서 설립.\n",
      "   - 주요 사업: 운동화, 의류, 장비, 액세서리 및 서비스의 설계, 개발, 마케팅 및 판매.\n",
      "   - 세계 최대의 운동화 및 의류 판매업체.\n",
      "\n",
      "2. **2023년 재무 성과**:\n",
      "   ...\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Turn 4/5\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "질문: State는 어떻게 사용하나요?\n",
      "예상 의도: DOC_QA\n",
      "\n",
      "[Router] 질문 분석 중: 'State는 어떻게 사용하나요?'\n",
      "  ✅ 분류된 의도: DOC_QA\n",
      "\n",
      "[Route] 현재 의도: DOC_QA\n",
      "  → 다음 노드: doc_qa\n",
      "\n",
      "[DOC_QA] 질문: 'State는 어떻게 사용하나요?'\n",
      "  [1/3] Retriever로 문서 검색 중...\n",
      "  ✅ 4개 문서 검색 완료\n",
      "  [2/3] LLM으로 답변 생성 중...\n",
      "  ✅ 답변 생성 완료 (781 characters)\n",
      "  [3/3] State 업데이트 중...\n",
      "  ✅ DOC_QA 노드 완료\n",
      "\n",
      "[결과]\n",
      "  실제 의도: DOC_QA\n",
      "  의도 일치: ✅\n",
      "  답변 길이: 781 characters\n",
      "  답변 미리보기: State는 LangGraph에서 현재 애플리케이션의 스냅샷을 나타내는 공유 데이터 구조입니다. State는 일반적으로 TypedDict를 사용하여 정의되며, 모든 노드와 엣지가 이 상태를 입력으로 사용합니다. State는 다음과 같은 방식으로 사용됩니다:\n",
      "\n",
      "1. **...\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "Turn 5/5\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "질문: 도움 주셔서 감사합니다!\n",
      "예상 의도: SMALL_TALK\n",
      "\n",
      "[Router] 질문 분석 중: '도움 주셔서 감사합니다!'\n",
      "  ✅ 분류된 의도: SMALL_TALK\n",
      "\n",
      "[Route] 현재 의도: SMALL_TALK\n",
      "  → 다음 노드: small_talk\n",
      "\n",
      "[SMALL_TALK] 대화: '도움 주셔서 감사합니다!'\n",
      "  [1/2] LLM으로 답변 생성 중...\n",
      "  ✅ 답변 생성 완료 (45 characters)\n",
      "  [2/2] State 업데이트 중...\n",
      "  ✅ SMALL_TALK 노드 완료\n",
      "\n",
      "[결과]\n",
      "  실제 의도: SMALL_TALK\n",
      "  의도 일치: ✅\n",
      "  답변 길이: 45 characters\n",
      "  답변 미리보기: 천만에요! 언제든지 도움이 필요하시면 말씀해 주세요. 어떤 부분에서 도와드릴까요?...\n",
      "\n",
      "================================================================================\n",
      "✅ 시나리오 3: Mixed (혼합) 완료\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "시나리오 3 결과 분석\n",
      "================================================================================\n",
      "\n",
      "의도 분류 정확도: 5/5 (100.0%)\n",
      "\n",
      "턴별 결과:\n",
      "--------------------------------------------------------------------------------\n",
      "Turn   | 예상           | 실제           | 일치    \n",
      "--------------------------------------------------------------------------------\n",
      "1      | SMALL_TALK   | SMALL_TALK   | ✅     \n",
      "2      | DOC_QA       | DOC_QA       | ✅     \n",
      "3      | SUMMARY      | SUMMARY      | ✅     \n",
      "4      | DOC_QA       | DOC_QA       | ✅     \n",
      "5      | SMALL_TALK   | SMALL_TALK   | ✅     \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "특징:\n",
      "  - 3가지 의도 모두 포함\n",
      "  - SMALL_TALK → DOC_QA → SUMMARY → DOC_QA → SMALL_TALK\n",
      "  - 가장 자연스러운 대화 시나리오\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cell 34: 4.5 시나리오 3 실행 (Mixed)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "scenario_3_results = run_scenario(\n",
    "    \"시나리오 3: Mixed (혼합)\",\n",
    "    scenarios[\"시나리오 3: Mixed (혼합)\"],\n",
    "    thread_id=\"scenario-3-mixed\"\n",
    ")\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# 결과 분석\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"시나리오 3 결과 분석\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "total_turns = len(scenario_3_results)\n",
    "correct_intents = sum(1 for r in scenario_3_results if r['intent_match'])\n",
    "accuracy = (correct_intents / total_turns * 100) if total_turns > 0 else 0\n",
    "\n",
    "print(f\"\\n의도 분류 정확도: {correct_intents}/{total_turns} ({accuracy:.1f}%)\")\n",
    "\n",
    "print(\"\\n턴별 결과:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Turn':<6} | {'예상':<12} | {'실제':<12} | {'일치':<6}\")\n",
    "print(\"-\" * 80)\n",
    "for r in scenario_3_results:\n",
    "    match_symbol = \"✅\" if r['intent_match'] else \"❌\"\n",
    "    print(f\"{r['turn']:<6} | {r['expected_intent']:<12} | {r['actual_intent']:<12} | {match_symbol:<6}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\n특징:\")\n",
    "print(f\"  - 3가지 의도 모두 포함\")\n",
    "print(f\"  - SMALL_TALK → DOC_QA → SUMMARY → DOC_QA → SMALL_TALK\")\n",
    "print(f\"  - 가장 자연스러운 대화 시나리오\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6644535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cell 35: 4.6 종합 평가\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "전체 시나리오 종합 평가\n",
      "================================================================================\n",
      "\n",
      "총 통계:\n",
      "  - 총 시나리오: 3개\n",
      "  - 총 턴 수: 13턴\n",
      "  - 의도 분류 정확도: 13/13 (100.0%)\n",
      "\n",
      "시나리오별 정확도:\n",
      "--------------------------------------------------------------------------------\n",
      "시나리오                 | 턴 수      | 정확도            \n",
      "--------------------------------------------------------------------------------\n",
      "시나리오 1               | 4        | 4/4 (100.0%)\n",
      "시나리오 2               | 4        | 4/4 (100.0%)\n",
      "시나리오 3               | 5        | 5/5 (100.0%)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "의도별 통계:\n",
      "--------------------------------------------------------------------------------\n",
      "의도              | 횟수        \n",
      "--------------------------------------------------------------------------------\n",
      "DOC_QA          | 7         \n",
      "SUMMARY         | 4         \n",
      "SMALL_TALK      | 2         \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "RAG 사용 통계:\n",
      "  - Context 사용: 11/13턴\n",
      "  - 예상: DOC_QA + SUMMARY에서만 사용\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cell 35: 4.6 종합 평가\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# 전체 결과 집계\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "all_results = {\n",
    "    \"시나리오 1\": scenario_1_results,\n",
    "    \"시나리오 2\": scenario_2_results,\n",
    "    \"시나리오 3\": scenario_3_results\n",
    "}\n",
    "\n",
    "total_all_turns = sum(len(results) for results in all_results.values())\n",
    "total_correct = sum(\n",
    "    sum(1 for r in results if r['intent_match'])\n",
    "    for results in all_results.values()\n",
    ")\n",
    "overall_accuracy = (total_correct / total_all_turns * 100) if total_all_turns > 0 else 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"전체 시나리오 종합 평가\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n총 통계:\")\n",
    "print(f\"  - 총 시나리오: {len(all_results)}개\")\n",
    "print(f\"  - 총 턴 수: {total_all_turns}턴\")\n",
    "print(f\"  - 의도 분류 정확도: {total_correct}/{total_all_turns} ({overall_accuracy:.1f}%)\")\n",
    "\n",
    "# 시나리오별 정확도\n",
    "print(f\"\\n시나리오별 정확도:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'시나리오':<20} | {'턴 수':<8} | {'정확도':<15}\")\n",
    "print(\"-\" * 80)\n",
    "for name, results in all_results.items():\n",
    "    total = len(results)\n",
    "    correct = sum(1 for r in results if r['intent_match'])\n",
    "    accuracy = (correct / total * 100) if total > 0 else 0\n",
    "    print(f\"{name:<20} | {total:<8} | {correct}/{total} ({accuracy:.1f}%)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# 의도별 통계\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "intent_stats = Counter()\n",
    "for results in all_results.values():\n",
    "    for r in results:\n",
    "        intent_stats[r['actual_intent']] += 1\n",
    "\n",
    "print(f\"\\n의도별 통계:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'의도':<15} | {'횟수':<10}\")\n",
    "print(\"-\" * 80)\n",
    "for intent, count in intent_stats.most_common():\n",
    "    print(f\"{intent:<15} | {count:<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# Context 사용 통계\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "total_context_used = sum(\n",
    "    sum(1 for r in results if r['context_used'])\n",
    "    for results in all_results.values()\n",
    ")\n",
    "\n",
    "print(f\"\\nRAG 사용 통계:\")\n",
    "print(f\"  - Context 사용: {total_context_used}/{total_all_turns}턴\")\n",
    "print(f\"  - 예상: DOC_QA + SUMMARY에서만 사용\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d4bd049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Cell 36: 4.7 메모리 동작 확인\n",
      "================================================================================\n",
      "\n",
      "각 시나리오의 메모리 상태:\n",
      "\n",
      "시나리오 1 (thread_id: scenario-1-doc-qa)\n",
      "  - 저장된 메시지: 8개\n",
      "  - 대화 턴 수: 4턴\n",
      "  - 마지막 의도: DOC_QA\n",
      "\n",
      "시나리오 2 (thread_id: scenario-2-summary)\n",
      "  - 저장된 메시지: 8개\n",
      "  - 대화 턴 수: 4턴\n",
      "  - 마지막 의도: DOC_QA\n",
      "\n",
      "시나리오 3 (thread_id: scenario-3-mixed)\n",
      "  - 저장된 메시지: 10개\n",
      "  - 대화 턴 수: 5턴\n",
      "  - 마지막 의도: SMALL_TALK\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Cell 36: 4.7 메모리 동작 확인\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "# 각 시나리오의 메모리 상태 확인\n",
    "# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "thread_ids = [\n",
    "    (\"scenario-1-doc-qa\", \"시나리오 1\"),\n",
    "    (\"scenario-2-summary\", \"시나리오 2\"),\n",
    "    (\"scenario-3-mixed\", \"시나리오 3\")\n",
    "]\n",
    "\n",
    "print(\"\\n각 시나리오의 메모리 상태:\\n\")\n",
    "\n",
    "for thread_id, scenario_name in thread_ids:\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    \n",
    "    try:\n",
    "        # State 가져오기\n",
    "        state = app.get_state(config)\n",
    "        \n",
    "        # 메시지 수 계산\n",
    "        message_count = len(state.values.get('messages', []))\n",
    "        turns = message_count // 2  # Human + AI 페어\n",
    "        \n",
    "        print(f\"{scenario_name} (thread_id: {thread_id})\")\n",
    "        print(f\"  - 저장된 메시지: {message_count}개\")\n",
    "        print(f\"  - 대화 턴 수: {turns}턴\")\n",
    "        print(f\"  - 마지막 의도: {state.values.get('intent', 'N/A')}\")\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{scenario_name}: ⚠️ State 가져오기 실패 - {e}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8894bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_interface():\n",
    "    \"\"\"대화형 인터페이스\"\"\"\n",
    "    import uuid\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LangGraph 인지 아키텍처 챗봇\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"명령어:\")\n",
    "    print(\"  - 'exit' / '종료': 종료\")\n",
    "    print(\"  - 'reset': 대화 초기화\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 초기 thread_id\n",
    "    thread_id = f\"chat-{uuid.uuid4().hex[:8]}\"\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    \n",
    "    turn_count = 0\n",
    "    \n",
    "    while True:\n",
    "        # 사용자 입력\n",
    "        user_input = input(f\"\\n[Turn {turn_count + 1}] 질문: \").strip()\n",
    "        \n",
    "        if not user_input:\n",
    "            continue\n",
    "        \n",
    "        # 종료\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"종료\"]:\n",
    "            print(f\"\\n총 {turn_count}턴 대화 완료. 종료합니다.\")\n",
    "            break\n",
    "        \n",
    "        # 초기화\n",
    "        if user_input.lower() == \"reset\":\n",
    "            thread_id = f\"chat-{uuid.uuid4().hex[:8]}\"\n",
    "            config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "            turn_count = 0\n",
    "            print(f\"✅ 대화 초기화 완료 (새 thread_id: {thread_id})\")\n",
    "            continue\n",
    "        \n",
    "        # 그래프 실행\n",
    "        try:\n",
    "            initial_state = {\n",
    "                \"messages\": [HumanMessage(content=user_input)],\n",
    "                \"query\": user_input,\n",
    "                \"intent\": \"\",\n",
    "                \"context\": \"\"\n",
    "            }\n",
    "            \n",
    "            result = app.invoke(initial_state, config=config)\n",
    "            \n",
    "            # 결과 출력\n",
    "            intent = result['intent']\n",
    "            answer = result['messages'][-1].content\n",
    "            \n",
    "            print(f\"\\n[의도: {intent}]\")\n",
    "            print(f\"{answer}\")\n",
    "            \n",
    "            turn_count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ 오류: {e}\")\n",
    "\n",
    "# chat_interface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c1aa7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "youngha-nKRCD7e9-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
